---
title: "Local Linear Regression"
format:
    html:
        theme: darkly
        max-width: 800px
        fontsize: 12pt
subtitle: "Lesson 1.3, Applied Machine Learning"
---

[Course Homepage](https://politicalscience.github.io/ml)

## Table of Contents {#contents}

1.  [Local Linear Regressions](#local)

2.  [Local Linear Regressions in R](#r)

------------------------------------------------------------------------

Remember to load tidyverse.

```{r, message = FALSE}
library(tidyverse)
```

Let us also load the dataset we will be using for these examples (feel free to load your own dataset)

```{r, message = FALSE}
df <- read_csv("voctaxdata.csv")
```

------------------------------------------------------------------------

[Table of Contents](#contents) \| [Course Homepage](https://politicalscience.github.io/ml)

# Local Linear Regressions {#local}

Local regression models don't use some transformation function $f$ to change the linear model (unlike [polynomial models](https://politicalscience.github.io/ml/1-1.html)).

Instead, Local Linear Regression estimates the relationship between $x$ and $y$, at different points in the range of $x$.

-   Let us define a specific point in the range of $x$ as $x_0$

-   For each specific point $x_0$, we fit a linear regression model, but only with points within some short distance on either side of $x_0$.

-   This fitted local regression isn't a normal regression: instead, we weight points closer to $x_0$, meaning points closer to $x_0$ will have a bigger effect on the local regression slope than points further away from $x_0$

-   To determine how many points around $x_0$ to include in the local regression, we introduce the parameter span, $s$

-   When the span $s$ is larger, that means more values around $x_0$ are considered, meaning a less "flexible" model that doesn't fit the local alterations as close, but fits the broad patter better. When the span $s$ is smaller, that means less values around $x_0$ are considered, meaning a more "flexible" model that fits the data closer, but sometimes overfits the data.

-   With each point $x_0$ getting its own local regression, we can then stitch together these local regressions to get a prediction function.

<br />

Below is a figure showcasing how local regression works. At some specific point of $x$, $x_0$, showed by the vertical red line, we consider the surrounding points (showed with their weights in yellow), and produce a local linear regression. We then stitch these local regressions together to get a prediction function.

![](localregression.png)

<br />

Local linear regressions are considered excellent for fitting smooth functions without too many dimensions (ex. less than 4 independent variables). However, as the number of dimensions increase, it becomes less effective of a prediction method.

<br />

------------------------------------------------------------------------

[Table of Contents](#contents) \| [Course Homepage](https://politicalscience.github.io/ml)

# Local Linear Regressions in R {#r}

Remember to load tidyverse.

```{r, message = FALSE, eval = FALSE}
library(tidyverse)
```

Let us also load the dataset we will be using for these examples (feel free to load your own dataset)

```{r, message = FALSE, eval = FALSE}
df <- read_csv("voctaxdata.csv")
```

<br />

#### Creating the Model in R

We can run a local linear regression with the functions **loess()**. The syntax is as follows:

```{r, eval = FALSE}
loess_model <- loess(Y ~ X1 + X2, data = df, span = 0.5)

#summary() for output
summary(loess_model)
```

These are the parts of the syntax that can be altered:

-   **loess_model** is the variable I am saving my model to. *You can name this anything you want to.*

-   **Y** is the Y variable (Dependent variable) you are trying to predict, and **X1 + X2** are the X variables (independent variable) you are using to get your prediction. *Replace these with the variables you want to use.*

    -   NOTE: Always put the Y variable before the X variable. Separate the two with a tilda **\~**
    -   NOTE: You can add more simply by using a **+** sign and adding another variable.

-   **Span = 0.5** function represents the span $s$. *You can change this to anything you want to*.

    -   We will discuss how to choose the right polynomial in the next lesson about model selection.

-   **df** is the name of the data frame that I am drawing these X and Y variables from. *Replace this with the name of your data frame.*

<br />

#### Visualisation in R

We can visualise the line we just graphed with the following syntax:

```{r, eval = FALSE}
df %>%
  ggplot(aes(x = X_variable, y = Y_variable)) +
  geom_point() +
  geom_smooth(method = "loess", color = "red")
```

These are the parts of the syntax that can be altered:

-   **df** is the name of the data frame that I am drawing these X and Y variables from. *Replace this with the name of your data frame.*

-   **X_variable** is the X variable, and **Y_variable** is the Y variable. *Replace these with the variables you want to use.*

<br />

#### Prediction in R

If we are interested in prediction, we can use the **predict()** function. You can predict in-sample data by setting **newdata** = the data frame you used for regression. You can predict out-of-sample data by using a dataframe with the same variables but new values. The syntax is as follows:

-   Note: this syntax for prediction works in general for any type of model, not just local regressions.

```{r, eval = FALSE}
#create new df for comparison of actual and prediction
df_results <- df %>%
  select(Y) #optional, may help with readability

# newdata is what values of X1, X2... to predict for.
df_results$prediction <- predict(loess_model, newdata = df)

# brief glimpse of the results
head(df_results)
```

These are the parts of the syntax that can be altered:

-   **df_results** is the results data frame I am creating. *You can name this anything you want to.*

-   **Y** is the Y variable I am trying to predict. *Replace this with the name of your Y variable.*

-   **loess_model** is the variable I am saving my linear regression model to. *You can name this anything you want to.*

-   **df** is the name of the data frame that houses the $x$ values I want to predict for. *Replace this with the name of your data frame with the* $x$ *values you want to predict for.*

<br />

#### Example in R

Take the example of the relationship between **export volume** and the **globalisation of the economy:**

```{r}
loess_model <- loess(econglobal ~ export, data = df, span = 0.5)

summary(loess_model)
```

The default output doesn't tell us much information, but we can use the Residual Standard Error to measure performance in-sample.

Let us graph the relationship as follows:

```{r}
df %>%
  ggplot(aes(x = export, y = econglobal)) +
  geom_point() +
  geom_smooth(method = "loess", color = "red")
```

Let us generate prediction values for our in-sample, and compare them to the real $y$ values:

```{r}
#create new df for comparison of actual and prediction
df_results <- df %>%
  select(econglobal) #optional, may help with readability

# newdata is what values of X1, X2... to predict for.
df_results$prediction <- predict(loess_model, newdata = df)

# brief glimpse of the results
head(df_results)
```

<br />

------------------------------------------------------------------------

[Table of Contents](#contents) \| [Course Homepage](https://politicalscience.github.io/ml)