---
title: "Matrices"
format:
    html:
        theme: darkly
        max-width: 800px
        fontsize: 12pt
subtitle: "Lesson 4.3, Maths for Political Science"
---

[Course Homepage](https://politicalscience.github.io/math)

## Table of Contents {#contents}

1.  [Introduction to Matrices](#intro)
2.  [Types of Matrices](#types)

------------------------------------------------------------------------

[Table of Contents](#contents) \| [Course Homepage](https://politicalscience.github.io/math)

# Introduction to Matrices {#intro}

A matrix is a collection of scalars, put in some coherent order:

-   Matrices have rows and columns. The dimensions are rows (horizontal) by columns (vertical).

-   Just like vectors, matrices have elements - each scalar in the matrix is an element.

Matrices are generally indicated with a capital letter.

-   For example, matrix $A$

<br />

For example, take the following matrix:

$$
A_{3 \times 2} = 
\begin{bmatrix}
2 & 1 \\
1 & 5 \\
3 & 7
\end{bmatrix}
$$

This matrix has 3 rows and 2 columns (3 by 2).

-   We can identify a specific value within the matrix by referencing its row number, then column number

-   For example, $a_{1,2}$ would be the value in the 1st row and 2nd column of the matrix $A$, which is $1$.

<br />

Matrices can be viewed in 2 ways:

-   As a combination of a few horizontal vectors (for example, in the above matrix $A$, it would be a combination of 3 horizontal vectors with 2 dimensions).

-   Or as a combination of a few vertical vectors (for example, in the above matrix $A$, it would be a combination of 2 vertical vectors with 3 dimensions).

<br />

The combination of vertical vectors is more common in statistics, as our datasets tend to have one variable per column, and each variable is a vector.

-   So each variable vector takes up one column

-   Our matrix of all independent variables is usually labeled matrix $X$

<br />

------------------------------------------------------------------------

[Table of Contents](#contents) \| [Course Homepage](https://politicalscience.github.io/math)

# Types of Matrices {#types}

There are a few types of matrices that will frequently pop up in linear algebra and statistics. This section gives a brief overview of a few that you should be aware of.

<br />

#### Square Matrices

Square matrices have the same number of rows and columns... hence making a square.

-   These are common because a lot of matrix algebra, such as inversion, require square matrices.

<br />

For example, matrix $A$ below is a square matrix:

$$
A_{2 \times 2} = 
\begin{bmatrix}
2 & 1 \\
1 & 5
\end{bmatrix}
$$

<br />

#### Zero Matrix

The zero matrix is a matrix, where all elements are zeroes (every value is 0).

<br />

#### Diagonal Matrices

Diagnoal Matrices are matrices with only non-zero values along the diagonal.

-   They typically are also square matrices.

<br />

For example, matrix $B$ is a diagonal matrix:

$$
B_{3 \times 3} = 
\begin{bmatrix}
2 & 0 & 0 \\
0 & 5 & 0\\
0 & 0 & 3
\end{bmatrix}
$$

<br />

#### Identity Matrix

The identity matrix is when we have a diagonal matrix, where all the values on the diagonal are one.

-   This is very frequently appearing in linear algebra, and is usually denoted with a capital $I$

-   When you multiply the identity matrix times any other matrix, you get back that matrix (just like when you multiply by 1).

<br />

For example, matrix $I$ is a identity matrix:

$$
I_{3 \times 3} = 
\begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0\\
0 & 0 & 1
\end{bmatrix}
$$

<br />

#### Lower/Upper Triangular Matrices

Lower and Upper Triangular Matrices are matrices that only have non-zero values above or below the diagonal (diagonal inclusive).

-   Lower is when the values are below the diagonal

-   Upper is when the values are above the diagonal.

-   Note below how the resulting matrix is a triangle, hence its name.

<br />

For example, matrix $C$ is a Lower Triangular Matrix:

$$
C_{3 \times 3} = 
\begin{bmatrix}
1 & 0 & 0 \\
2 & 4 & 0\\
5 & 3 & 1
\end{bmatrix}
$$

<br />

#### Submatrix

A submatrix is the resulting matrix, after removing a row and column from the original matrix.

-   This is useful for determinants.

<br />

For example, $D$ is a submatrix of the above $C$ matrix after we remove row $1$ and column $3$:

$$
D_{2 \times 2} = 
\begin{bmatrix}
2 & 4\\
5 & 3
\end{bmatrix}
$$

<br />

#### Idempotent Matrix

Idempotent matrix is one, where you multiply by itself, you still get the same matrix.

-   Ex: Matrix $A$ is an Indempotent matrix if $A \times A = A$

-   Thus, additional transformations don't do anything further.

<br />

#### Singular/Non-Singular Matrices

Singular matrices are one, whose determinant is 0. Non-Singular Matrices are one, whose determinant is non-0.

-   This will make more sense when we go over determinants.

<br />

Notably, a singular matrix cannot be inverted, while a non-singular matrix can be inverted.

-   Inverted matrices are labeled as: $A^{-1}$

-   Inversions mean that $A \times A^{-1} = 1$

<!-- -->

-   This will become important later, as it helps solving systems of equations.

<br />

#### Block/Partitioned Matrix

A block/partion matrix, is one, which you can take a big matrix, and put it into smaller blocks.

-   Basically, you can represent the matrix as a matrix of matrices.

<br />

For example, take the following matrix $Z$, with $X, Y, W, V$ being matrices in their own right:

$$
Z_{4 \times 4} = 
\begin{bmatrix}
X_{2 \times 2} & Y_{2 \times 2}\\
W_{2 \times 2} & V_{2 \times 2}
\end{bmatrix}
$$

<br />

A diagonal block matrix is a block matrix, but with only non-zero values on the diagonal. For example, matrix $M$ below is a diagonal block matrix:

$$
M_{4 \times 4} = 
\begin{bmatrix}
N_{2 \times 2} & 0\\
0 & O_{2 \times 2}
\end{bmatrix}
$$

<br />

#### Orthogonal Matrices

An orthogonal matrix is one that has its columns perpendicular to each other.

-   Remember, we can imagine each column to be a vector. Then, we can graphically represent each vector.

-   The identity matrix is a orthogonal matrix. Why? Well, the identity matrix is just 3 different vectors, one with $x=1$, one with $y=1$, and one with $z=1$. We know that the axes $x,y,z$ are perpendicular to each other.

<br />

Another example of a simple Orthogonal Matrix is matrix $J$ below:

$$
J_{3 \times 3} = 
\begin{bmatrix}
0 & 4 & 0 \\
3 & 0 & 0\\
0 & 0 & 7
\end{bmatrix}
$$

<br />

#### Orthonormal Matrices

An orthonormal matrix is an orthogonal matrix, but all lengths are one.

-   The identity matrix is an example of both an orthonormal and orthogonal matrix.

-   The above example matrix $J$ is not orthonormal, because while it is orthogonal, the lengths are not 1.

<br />

------------------------------------------------------------------------

[Table of Contents](#contents) \| [Course Homepage](https://politicalscience.github.io/math)