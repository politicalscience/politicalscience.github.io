# Causal Inference

So far, we have introduced multiple estimators to help estimate parameters that describe the relationships between variables.

In this chapter, our goal is to go from relationships/correlation to causation. First, we introduce the popular causal frameworks and causal estimands. Then, we discuss the issue with selection bias, and why correlation is not causation. Finally, we discuss randomisation as a method to establish causality.

<br />

## Potential Outcomes Framework

A lot of social science and science is about understanding the causes of things. This involves understanding how some treatment variable $D$ causes some outcome variable $Y$. We call our treatment variable $D$. For each unit $t$, they have a treatment status of $D_t$:

$$
D_t = \begin{cases}
1 & \text{if unit t received the treatment} \\
0 & \text{if unit t did not receive the treatment}
\end{cases}
$$

Now, imagine that there are two parallel worlds. In one of these parallel worlds, unit $t$ receives the treatment $D_t = 1$. In the other parallel world, unit $t$ does not receive the treatment $D_t = 0$. Everything about these two parallel worlds besides $D_i$ is identical. The outcome $Y$ value in these two worlds is called the potential outcomes.

::: {#def-potoutcomes style="border-style: solid; border-radius: 8px; border-width: 0.5px; padding-top: 5px;   padding-right: 5px; padding-bottom: 5px; padding-left: 5px;"}
## Potential Outcomes

The potential outcomes $Y_t(d)$ for unit $t$ are the $Y$ values in the two identical parallel worlds besides the $D_t$ value.

$$
Y_t^{(d)} = \begin{cases}
\pt & D_t = 1\text{ parallel world outcome Y value for unit t} \\
\pc & D_t = 0\text{ parallel world outcome Y value for unit t} \\
\end{cases}
$$

To make clear when talking about potential outcomes, I will always highlight them in purple.
:::

::: {.callout-note collapse="true" appearance="simple"}
## Stable Unit Treatment Value Assumption

The above mentioned potential outcomes framework depends on the stablue unit treatment value assumption (SUTVA).

It basically says that unit $t$'s potential outcomes $Y_t(1)$ and $Y_{t}(0)$ are not affected in any way by another unit $j$'s treatment status $D_j$. Basically, changing other individual's treatment status has no effect on an individual's own outcomes.

If SUTVA is violated, then our nice two parallel worlds example no longer is accurate. This is because if SUTVA is violated, unit $t$ now has the potential outcomes of themselves receiving $D_t = 1, 0$, but also other people $D_j = 0, 1$. This will make the number of outcomes grow massively (especially if multiply other units affect an individual).

Common causes of SUTVA violations include:

-   Spill-over effects: If we are testing a new curriculum, one student $j$ getting the new curriculum may teach their friend $t$ the new curriculum, which means if student $j$ got or did not get the new curriculum would affect student $t$'s outcomes.
-   Dilution: For example, in vaccines, there is herd immunity. That means other people getting the vaccines also improves my health outcomes.
:::

If we know the two hypothetical parallel worlds are identical to each other [except]{.underline} for treatment $D_t$, then we know any difference in $Y$ outcomes between the two worlds must be a result of treatment $D$. This introduces us to the causal estimands - the true causal effects in the population:

::: {.panel-tabset .nav-pills}
## ITE

::: {#def-ite}
## Individual Treatment Effect

The individual treatment effect of treatment $D$ on $Y$, for a specific unit $i$, is given by the difference between the potential outcomes.

$$
\tau_t = \pt - \pc
$$
:::

## ATE

::: {#def-ate}
## Average Treatment Effect

The ATE is the average individual treatment effects $\tau_i$ in the population.

$$
\tau_{ATE} = \E(\tau_t) \  = \  \E(\pt - \pc)  \ = \  \E \pt - \E \pc
$$
:::

## ATT

::: {#def-att}
## Average Treatment Effect on the Treated

The ATT is the average individual treatment effect $\tau_i$ for only units that were assigned to the treatment group $D_i = 1$:

$$
\tau_{ATT} = \E(\tau_t | D_t = 1) \ = \ \E(\pt - \pc | D_t = 1)
$$
:::

## ATU

::: {#def-atu}
## Average Treatment Effect on the Untreated

The ATU is the average individual treatment effect $\tau_i$ for only units that were assigned to the control group $D_i = 0$:

$$
\tau_{ATT} = \E(\tau_t | D_t = 0) \ = \ \E(\pt - \pc | D_t = 0)
$$
:::

## CATE

::: {#def-cate}
## Conditional Average Treatment Effect

The CATE is the average treatment effect, conditional on some other characteristic/covariate $X$ value:

$$
\tau_{CATE}(x) = \E(\tau_t| X = x) \ = \ \E(\pt - \pc|X=x)
$$

This estimand is also sometimes called the local average treatment effect (LATE).
:::
:::

However, there is an issue: in the real world, we obviously do not have two hypothetical parallel worlds. We only have one world - either unit $t$ gets treated $D_t = 1$ or unit $t$ does not get treated $D_t = 0$. The world we actually live in is called the observed outcome, and the parallel world we do not see is called the counterfactual. The fact we cannot observe the counterfactual is called the **fundamental problem of causal inference**.

::: {#def-observedoutcomes style="border-style: solid; border-radius: 8px; border-width: 0.5px; padding-top: 5px;   padding-right: 5px; padding-bottom: 5px; padding-left: 5px;"}
## Observed Outcomes and Counterfactuals

The observed outcome $Y_t$ that we actually see for a unit $t$ can be given by a function of potential outcomes:

$$
Y_t = D_t \cdot \pt + (1-D_i) \cdot \pc
$$

If we plug in the treatment status $D_t = 0, 1$ of unit $t$ into the above equation, we get observed outcomes

$$
Y_t = \begin{cases}
\pt & \text{if} D_i = 1 \\
\pc & \text{if} D_i = 0
\end{cases}
$$

The potential outcome that is not observed is the counterfactual outcome.
:::

<br />

## Structural Causal Models

An alternative causal framework, pioneered by Pearl, is called the structural causal models. This framework uses graphical models (called directed acyclic graphs) to illustrate causality.

![](images/clipboard-3021970542.png){fig-align="center" width="35%"}

Every causal graph illustrates how different variables are connected to each other. Each graph contains:

1.  Nodes: These are letters that represent different variables.
2.  Directed Edges: these are arrows that encode causal theories between the variables. For example, if you believe $Z$ causes $D$, you would draw an arrow $Z \rightarrow D$. These connections are either observable (solid lines) or unobservable (dashed lines).

**Paths** are any route between any two variables, that do not have to follow the direction of the arrows. For example, in the figure above, between $D$ and $Y$, there are 3 paths:

1.  The direct path $D \rightarrow Y$.
2.  The inderect/backdoor path $D \leftarrow Q \rightarrow Y$.
3.  The indirect/backdoor path $D \leftarrow Z \leftarrow W \rightarrow Y$.

The goal in causal inference is to get rid of all the indirect/backdoor paths, allowing us to isolate the direct relationship between $D$ and $Y$. There are two ways to isolate the direct relationship: external intervention and blocking paths.

::: {.panel-tabset .nav-pills}
## External Intervention

One way to isolate a causal path is through an **external intervention**. For example, in the figure below, variable $D$ is directly caused by $Q$ and $Z$. This allows indirect paths between $D$ and $Y$ to flow between $Q$ and $Z$.

![](images/clipboard-3951308334.png){fig-align="center" width="35%"}

However, by externally determining $D$ (represented with the operator $d_0$), we can break the paths $Q \rightarrow D$ and $Z \rightarrow D$. This is because if we are deciding who gets $D$ (such as by randomisation), that means we are deciding $D$, not $Q$ or $Z$. This will allow us to block backdoor paths, and our new diagram will be:

![](images/clipboard-2834742175.png){fig-align="center" width="35%"}

And thus, we have isolated the causal relationship.

## Blocking Paths

On the other hand, we can block indirect/backdoor paths through conditioning on a set of variables/nodes $\set X$. A set of nodes $\cal X$ blocks a path if one of two is true:

1.  A path is blocked if our set of conditioning nodes $\set X$ includes at least one arrow-emitting node within that path.
2.  A path is blocked if the path contains a collision node (where multiple arrows point into it), and that collision node is not included in our set of conditioning nodes $\set X$.

![](images/clipboard-3519172210.png){fig-align="center" width="40%"}

For example, in the figure above, we can see:

1.  The path $D \rightarrow P \rightarrow Y$ is blocked by a set $\set X = \{P\}$, since $P$ is one arrow emitting node within this path.
2.  The path $D \leftarrow M \rightarrow Y$ is blocked by a set $\set X = \{M\}$, because $M$ is one arrow emitting node within this path.
3.  The path $D \leftarrow Z \rightarrow M \rightarrow Y$ is blocked by either $\set X = \{M\}, \{Z\}$ or $\{M, Z\}$.
4.  The path $D \leftarrow Z \rightarrow M \leftarrow Q \rightarrow Y$ is blocked by an empty set $\set X = \varnothing$, because $M$ is a collider node in this path and we do not need to include it.

We will discuss the idea of blocking paths more in the next chapter.
:::

<br />

## Selection Bias

You always here the saying - correlation is not causation. But what does that actually mean? A simple model of correlation $\rho$ is finding how observed $Y$ changes when $D$ changes. More specifically, we want to find the differences in conditional expectations (given by @def-condexp) of observed $Y_t$ values for when $D_t = 1$ and $D_t = 0$:

$$
\rho_{D, Y} = \E(Y_t|D_t = 1) - \E (Y_t | D_t = 0)
$$Now, let us do some algebra. First, we know that $Y_t|D_t = 1$ is the observed potential outcome $\pt$. We also know that $Y_t|D_t = 0$ is the observed potential outcome $\pc$. Thus, we can rewrite the above to

$$
\rho_{D, Y} = \E(\pt|D_i = 1) - \E(\pc|D_i = 0)
$$

Now, let us do an algebra trick. We know that adding a zero doesn't change the equality of the equation. Let us add the term $\E(\pc|D_t = 1)$, but then also subtract that term, so we are essentially adding a 0. Then we get

$$
\begin{align}
\rho_{D, Y} = \E(\pt &|D_t = 1) - \E(\pc|D_t = 0) \\ 
& + \E(\pc|D_t = 1) - \E(\pc|D_t = 1)
\end{align}
$$

Let us rearrange the order of the terms to get

$$
\begin{align}
\rho_{D, Y} & = \overbrace{\E(\pt|D_t = 1) - \E(\pc|D_t = 1)}^{\tau_{ATT}} \\
& \qquad \qquad \qquad \underbrace{+ \E(\pc|D_t = 1) - \E(\pc|D_t = 0)}_{\text{selection bias}}
\end{align}
$$ {#eq-selectionbias}

We can see that according to @def-att, the first part of this correlation between $D$ and $Y$ is the ATT, one of the causal estimands. However, the correlation $\rho_{D,Y}$ does not only equal the $\tau_{ATT}$, as there is an extra bit, the *selection bias*. If this selection bias is not 0, then our correlation is clearly not equal to our ATT.

Let us look at the selection bias term more carefully:

$$
\underbrace{+ \E(\pc|D_t = 1) - \E(\pc|D_t = 0)}_{\text{selection bias}}
$$

The first part is the average potential outcome under parallel world $D_t = 0$ for the units that were assigned to treatment $D_t = 1$. The second part is the average potential outcome under parallel world $D_t = 0$ for units that were assigned to control $D_t = 0$.

If this term is non-zero, that means the control group and treatment group have different average $\pc$ values. That means, before our experiment had even started, the control and treatment groups had different baseline potential outcome $\pc$. If for example, the treatment group $D_t = 1$ initially had a very low $\pc$, even after treatment with true effect $+\tau$, their outcome $Y_t$ may still be lower than people who didn't get the treatment. So, our correlation $\rho_{D,Y}$ would pick up a negative treatment effect, when the actual treatment effect is positive $+\tau$.

A good intuitive example is the question: *does going to the hospital improve your life expectancy*? If we were to just collect correlation data, we would see that actually, people who went to the hospital have lower life expectancy.

But, that is because people who go to the hospital in the first place already have low life expectancy $\pc$ compared to people who didn't go. The hospital will cause these people with low life expectancy to have longer lives (treatment effect $\tau$), but even with $\pc + \tau$, their life expectancy may still be lower than the $\pc$ of the group who never went to the hospital.

Thus, our correlation measure shows a negative effect of going to the hospital on life expectancy, when in reality, going to the hospital does boost life expectancy, its just people who choose to go to the hospital start off with lower life expectancy than those who do not go.

<br />

## Confounders

The reason for this difference in pre-experiment $\pc$ is a third variable $X$ is causing people to go to select treatment $D$ more frequently, and also has some effect on $Y$. $X$ is thus causing **selection bias**. An $X$ that causes selection bias is called a confounder.

::: {#def-confounder style="border-style: solid; border-radius: 8px; border-width: 0.5px; padding-top: 5px;   padding-right: 5px; padding-bottom: 5px; padding-left: 5px;"}
## Confounder

A confounder is a third variable $X$ that causes selection into treatment $D$ and causes changes in outcome $Y$. If there is such a variable, this creates selection bias, and makes correlation not equal causation.
:::

<br />

For example, there is a well known correlation in the real world that *ice cream sales* are strongly correlated with *shark attacks*. So does *ice cream sales* actually cause more *shark attacks*?

The answer is (likely) no. The reason we see this correlation is because of a third variable - the *weather*. When the *weather* is warm, more people buy ice cream, and more people go to the ocean, hence increasing the amount of shark attacks.

*Weather* is a third variable that we consider a confounder, as it affects both *ice cream sales* and *shark attacks*. There is actually no relationship between *ice cream sales* and *shark attacks* - the perceived correlation is caused by the confounder *weather*.

Our goal in causal inference is to eliminate the effects of the confounders and isolate the effects between treatment and outcome. We can also visualise confounders in a structural causal model:

![](images/clipboard-2044932443.png){fig-align="center" width="35%"}

For example, the figure above, $X$ is confounding the relationship between $D \rightarrow Y$. This is because both $X$ is correlated with $D$ and $Y$. When we naively estimated the correlation $\rho_{D,Y}$, we are estimating the relationship between $D \rightarrow Y$ [and]{.underline} the relationship $D \leftarrow X \rightarrow Y$ . But, the true causal effect is $D \rightarrow Y$, without the other backdoor path. For accurate causal estimation, we need some way to "block" the path through $X$.

Why isn't $V$ a confounder? Well, $V$ does not cause selection into $D$, as the arrow direction shows that $D$ causes $V$. Thus, $V$ is not causing selection bias. We do not care about variables caused by $D$.

<br />

## Randomisation

One way we can eliminate selection bias is through randomly assigning our subjects to either treatment $D_t = 1$ or control $D_t = 0$. Randomisation implies that the assignment probabilities do not depend on the potential outcomes - the values of $\pc$ and $\pt$ do not affect the probability of a unit $t$ getting put into treatment $D_t = 1$ or control $D_t = 0$.

$$
\P(D_t = 1 | \pc) = \P(D_t = 1 | \pt)  =  \P(D_t = 1)
$$

This fact implies the critical assumption of randomisation, independence.

::: {#def-randomisation style="border-style: solid; border-radius: 8px; border-width: 0.5px; padding-top: 5px;   padding-right: 5px; padding-bottom: 5px; padding-left: 5px;"}
## Independence

Randomisation, if done properly, implies independence. Independence, also called unconfoundedness or ignorability, is the statement that potential outcomes are independent of treatment:

$$
\pc, \pt \ind D_t
$$

This assumption, and the defintition of independence from @def-independence, implies that $\E Y_{t}(0)$ and $\E Y_{t}(1)$ are equal between treatment and control:

$$
\begin{align}
& \E(\pc|D_t = 1) \ = \ \E(\pc|D_t = 0) \ = \ \E \pc \\
& \E(\pt|D_t = 1) \ = \ \E(\pt|D_t = 0) \ = \ \E \pt
\end{align}
$$
:::

::: {.callout-note collapse="true" appearance="simple"}
## Checking if Independence is Met

When we are writing a paper, we might want to convince our readers that randomisation has indeed successfully been implemented, and that the assumption of independence has been met. The most common way to check this is with a **balance** check. We essentially consider a few likely confounders $X$. We then run a regression:

$$
X_t = \beta_0 + \beta_1 D_t + \eps_t
$$

$\beta_1$ will show the difference between $\E(X_t | D_t = 1)$ and $\E(X_t|D_t = 0)$. If $\beta_1$ is not statistically significantly different, then we can conclude the treatment and control groups are similar, and that randomisation has suceeded.

Do note that the important thing in randomisation (and the assumption of independence) is not that $X_t$ is random between treatment and control, but rather potential outcomes are random. Although, if $X_t$ is random between treatment and control, that generally implies potential outcomes are also random.
:::

We can prove that randomisation and the independence assumption allow us to eliminate the selection bias shown in @eq-selectionbias. Let us start with our correlation from @eq-selectionbias:

$$
\begin{align}
\rho_{D, Y} & = \overbrace{\E(\pt|D_t = 1)- \E(\pc|D_t = 1)}^{\tau_{ATT}} \\
& \qquad \qquad \qquad + \underbrace{\E(\pc|D_t = 1) - \E(\pc|D_t = 0)}_{\text{selection bias}}
\end{align}
$$

Using the properties of independence from @def-randomisation, we can get

$$
\begin{align}
\rho_{D, Y} & = \underbrace{\E(\pt|D_t = 1)- \E(\pc|D_t = 1)}_{\tau_{ATT}} + \underbrace{\E \pc - \E \pc}_{\text{selection bias}} \\
& = \underbrace{\E(\pt|D_t = 1)- \E(\pc|D_i = 1)}_{\tau_{ATT}} + 0
\end{align}
$$

Thus, we can see the assumption of independence has removed our selection bias, and allowed us to accurately calculate our $\tau_{ATT}$ simply by looking at the correlation $\rho_{D,Y}$.

We can also identify the ATE from our correlation $\rho_{D,Y}$, by simplifying once again using the properties implied by the assumption of independence from @def-randomisation:

$$
\begin{align}
\rho_{D, Y} & = \underbrace{\E(\pt|D_i = 1)- \E(\pc|D_i = 1)}_{\tau_{ATT}} \\
& = \underbrace{\E \pt - \E \pc}_{\tau_{ATE}}
\end{align}
$$

Which according to @def-ate, is the ATE. Thus, under randomisation, our correlation measure $\rho_{D, Y} = \tau_{ATT} = \tau_{ATE}$. Recall our correlation measure again $\rho_{D, Y}$ was simply a comparison of observed outcomes between treatment and control groups:

$$
\rho_{D, Y} = \E(Y_t|D_t = 1) - \E (Y_t | D_t = 0) = \tau_{ATE} = \tau_{ATT}
$$

Since $\rho_{D, Y}$ only requires observed outcomes (not potential), we can calculate $\rho_{D, Y}$, which is also equal to the ATE and ATT under randomisation. Thus, we have identified a way to find the ATE and ATT with just observed outcomes. This means that under randomisation, simple correlation models also give us causal effects.

<br />

## Randomised Experiments

So we have established that randomly assigning treatment and control can allow us to establish that correlation equals causation (under succesfull randomisation only).

But how can we actually implement this design? There are several different ways to do randomisation:

::: {.panel-tabset .nav-pills}
## Classic

The classic randomisation is the most common form of randomsiation.

We start out with $N$ total number of individuals/observations in our experiment. We first decide the number of individuals we want to assign to treatment, $N_1$. Frequently, $N_1$ is 50% of $N$.

Then, a random set of $N_1$ number individuals is assigned to treatment, and the remainder is sent to control. Now we have randomly assigned treatment and control individuals.

There is an issue: technically, not all units $t$ have an equal chance of being assigned to treatment. This is because once we assign $N_1$ of individuals to treatment, the remaining observations will have 0% chance of being assigned to treatment. Bernoulli Randomisation deals with this.

## Bernoulli

Bernoulli randomisation is another form of randomisation. Instead of specifying before-hand how many treated units $N_1$ you want, we let $N_1$ be un-fixed.

For every unit $t$, they have some probability $p$ of being assigned to treatment. We do this for every unit $t$.

The result is that every unit has an equal chance of being assigned to treatment and control, unlike classic randomisation. The downside is that if we run the procedure multiple times, the number of units treated $N_1$ will differ between each trial.

## Cluster

Cluster randomisation is when we randomly assign units (or have individuals naturally) in groups. Every unit within a group (called a cluster) will get the same treatment. We randomly sample the groups to get the treatment or control.

For example, we could randomise development treatment at the village level, or randomise treatment of a cirriculum at the school level.

The main reason for this is to prevent SUTVA violations. For example, imagine you are testing the effects of a new curriculum. If you randomise by each student, students will talk to their friends, and treated individuals may teach control individuals about the new curriculum. But by randomising by school (either an entire school gets or does not get the new curriculum), this concern is not a huge issue.

## Stratified

Stratified (also called blocked or conditional) randomisation are when randomisation occurs separately within levels of some covariates(s) $X$. Generally, you separate your sample of $N$ units into $J$ subgroups. For example, you could split people up into male or female, then randomly sample within each group, rather than everyone together.

The reason you might want to do this is to ensure that both your treatment and control are balanced. For example, let us say you have 4 subjects, with pre-treatment potential outcomes $\pc = \{2, 2, 8, 8\}$.

If you are randomly assigning, you have a 33% chance you end up with an assignment where $\{8, 8\}$ are placed in one group, and $\{2, 2\}$ are placed in another group. In this case, our treatment/control groups would be very different, and this would violate our independence assumption.

By stratifying our sample before into two subgroups, with group 1 being $\{2, 2\}$ and group 2 being $\{8,8\}$, and randomly sampling one from each group into treatment, we are guaranteed to have more balance.
:::

When we are writing a paper, we might want to convince our readers that randomisation has indeed successfully been implemented, and that the assumption of independence has been met. The most common way to check this is with a **balance** check. We essentially consider a few likely confounders $X$. We then run a regression:

$$
X_t = \underbrace{\beta_0 + \beta_1 D_t}_{\E(X_t|D_t)} + \eps_t
$$

$\beta_1$ will show the difference between $\E(X_t | D_t = 1)$ and $\E(X_t|D_t = 0)$. If $\beta_1$ is not statistically significantly different, then we can conclude the treatment and control groups are similar, and that randomisation has succeeded.

We can estimate the ATE in a randomisation setting where independence is met simply with a correlation measure, such as a [linear model](ols.qmd#the-classical-linear-model):

$$
Y_t = \underbrace{\alpha + \tau D_t}_{\E(Y_t | D_t)} + \eps_t
$$

Where $\tau$ can be estimated with OLS, GLS, or MLE (although OLS with robust standard errors is generally the preferred estimator). A difference-in-means estimator is also possible.

Significance testing will be done with a t-test (@def-ttest) like you do in OLS. [Robust standard errors](gls.qmd#robust-standard-errors) (to account for heteroscedasticity) should be used as a default, unless you can prove homoscedasticity is met. If you are using cluster randomisation, you should use cluster-robust standard errors. [Bootstrap inference](inference.qmd#nonparametric-bootstrap) is also a common choice if your sample size is quite small.

While the linear model is the best way to estimate the ATE specifically, if you are less concerned with the ATE, you can also use other models, such as the logistic model, poisson model, and many more. While the results may not be exactly the ATE, they can be interpreted causally if you are randomising.

<br />

## Randomisation Inference

While you can use a traditional t-test like in OLS, we can also do a different form of inference: randomisation inference. This assumes a certain form of null hypothesis, called the sharp null hypothesis:

$$
H_0^s: \pt = \pc, \quad H_a^s: \pt â‰  \pc
$$

This null hypothesis basically asserts that there is no treatment effect $\tau_t$ for any individual $t$ in the study.

Assuming $H_0^s$ is true, we can actually fully construct the potential outcomes $\pc, \pt$, since we know every unit has 0 individual treatment effect. Thus, for any unit $t$, their observed $Y_t = \pc = \pt$ if there is no treatment effect.

Since we can fully construct the potential outcomes, we can recreate the sampling distribution without asymptotic properties of our estimator, as we do not need the central limit theorem (@thm-clt).

First, we want to calculate the total number of randomisations possible. If we have $N$ total units, and $N_1$ in the treatment group and $N_0$ in the control group, we have

$$
\begin{pmatrix} N \\ N_1 \end{pmatrix} = \frac{N!}{N_1!N_0!}
$$

number of possible randomisation assignments. Then, for each randomisation assignment, we calculate the $\hat\tau$ of that randomisation.

![](images/clipboard-2586795073.png){fig-align="center" width="70%"}

And now with the $\hat\tau$ of every possible randomisation, we can plot it in a distribution to create the sampling distribution under the null hypothesis:

![](images/clipboard-993993851.png){fig-align="center" width="60%"}

Now, we essentially conduct a hypothesis test on this sampling distribution, and calculate the p-value as normal. If our result is significant, we have evidence to reject our sharp null hypothesis $H_0^s$.

The benefit of randomisation inference is that it is assumption free- we do not rely on asymptotic properties of estimators, which frequently require large sample sizes.

However, the downside of randomisation inference is that it only tests the sharp null hypothesis $H_0^s$. But this might not be the hypothesis we are actually interested in.
