<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Chapter 2: Causal Relationships and Confounding Variables</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="2_files/libs/clipboard/clipboard.min.js"></script>
<script src="2_files/libs/quarto-html/quarto.js"></script>
<script src="2_files/libs/quarto-html/popper.min.js"></script>
<script src="2_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="2_files/libs/quarto-html/anchor.min.js"></script>
<link href="2_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="2_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="2_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="2_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="2_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: true
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body>

<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Chapter 2: Causal Relationships and Confounding Variables</h1>
            <p class="subtitle lead">Econometric Methods (for Social Scientists)</p>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99">
    <h2 id="toc-title">Chapter 2: Causal Relationships and Confounding Variables</h2>
   
  <ul class="collapse">
  <li><a href="#correlation-and-causation" id="toc-correlation-and-causation" class="nav-link active" data-scroll-target="#correlation-and-causation">2.1: Correlation and Causation</a></li>
  <li><a href="#potential-outcomes-and-causal-effects" id="toc-potential-outcomes-and-causal-effects" class="nav-link" data-scroll-target="#potential-outcomes-and-causal-effects">2.2: Potential Outcomes and Causal Effects</a></li>
  <li><a href="#observed-outcomes-and-the-stable-unit-treatment-value-assumption" id="toc-observed-outcomes-and-the-stable-unit-treatment-value-assumption" class="nav-link" data-scroll-target="#observed-outcomes-and-the-stable-unit-treatment-value-assumption">2.3: Observed Outcomes and the Stable Unit Treatment Value Assumption</a></li>
  <li><a href="#causal-estimands" id="toc-causal-estimands" class="nav-link" data-scroll-target="#causal-estimands">2.4: Causal Estimands</a></li>
  <li><a href="#properties-of-estimators---unbiasedness-and-consistency" id="toc-properties-of-estimators---unbiasedness-and-consistency" class="nav-link" data-scroll-target="#properties-of-estimators---unbiasedness-and-consistency">2.5: Properties of Estimators - Unbiasedness and Consistency</a></li>
  <li><a href="#the-naive-estimator-and-proof-correlation-is-not-causation" id="toc-the-naive-estimator-and-proof-correlation-is-not-causation" class="nav-link" data-scroll-target="#the-naive-estimator-and-proof-correlation-is-not-causation">2.6: The Naive Estimator and Proof Correlation is not Causation</a></li>
  <li><a href="#selection-bias-and-confounding-variables" id="toc-selection-bias-and-confounding-variables" class="nav-link" data-scroll-target="#selection-bias-and-confounding-variables">2.7: Selection Bias and Confounding Variables</a></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>This chapter will introduce the idea of causal effects and causation. We will explore what a causal effect is, how to theoretically identify causal effects, and the dangers of using correlation as causation.</p>
<p>Topics: Potential Outcomes Framework, Causal Estimands, Properties of Estimators, Naive Estimator, Selection Bias, Confounding Variables</p>
<p><br></p>
<hr>
<p><a href="https://politicalscience.github.io/metrics/">Course Homepage</a></p>
<section id="correlation-and-causation" class="level1">
<h1>2.1: Correlation and Causation</h1>
<section id="correlation-is-not-causation" class="level3">
<h3 class="anchored" data-anchor-id="correlation-is-not-causation">Correlation is not Causation</h3>
<p>We defined what correlation was in <a href="https://politicalscience.github.io/metrics/causal/1.html#correlations-and-measuring-relationships-between-variables">section 1.1</a>. For review, these are the sources of correlation:</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition: Sources of Correlation
</div>
</div>
<div class="callout-body-container callout-body">
<p>There are three main reasons why two variables <span class="math inline">x</span> and <span class="math inline">y</span> may be correlated:</p>
<ol type="1">
<li>There is a causal effect of <span class="math inline">x</span> on <span class="math inline">y</span></li>
<li>A third variable, <span class="math inline">w</span>, causes both <span class="math inline">x</span> and <span class="math inline">y</span> to change (so there is no direct effect of <span class="math inline">x</span> on <span class="math inline">y</span>)</li>
<li>There is a causal effect of <span class="math inline">y</span> on <span class="math inline">x</span></li>
</ol>
<p>These causes can occur simultaneously at the same time. Thus, correlation is not causation, as correlation can be caused by other factors.</p>
</div>
</div>
<p><br></p>
<p>If our goal in econometrics is to find the causal effect of <span class="math inline">x \rightarrow y</span> (source #1 of correlation), we must eliminate the effects of the third variable <span class="math inline">w</span> (source #2 of correlation), and the reverse causality effect <span class="math inline">y \rightarrow x</span> (source #3 of correlation).</p>
<ul>
<li>Thus, we need some methods to eliminate sources #2 and #3 of correlation in order to accurately estimate the causal effect of <span class="math inline">x \rightarrow y</span>.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: Correlation is not Causation
</div>
</div>
<div class="callout-body-container callout-body">
<p>In the United States, <em>Ice Cream Sales</em> and <em>Number of Fatal Shark Attacks</em> are highly correlated variables. Does this mean that selling ice cream <strong>causes</strong> fatal shark attacks? No!</p>
<p>The reason this relationship exists is because of another variable - the <em>weather</em>. The weather (when sunny), causes both ice cream sales to rise, as well as causing more people to go to the beach, which then increases the number of fatal shark attacks.</p>
<p>This is a clear example of how correlation is not causation.</p>
</div>
</div>
<p><br></p>
</section>
<section id="key-terminology" class="level3">
<h3 class="anchored" data-anchor-id="key-terminology">Key Terminology</h3>
<p>Before we start discussing methods to eliminate the effect of third variables and reverse causality, we need to first understand what even is a causal effect. Let us define some key terminology:</p>
<ul>
<li>The variable which causes a causal effect is called the <strong>treatment</strong>, labelled <span class="math inline">D</span> (sometimes <span class="math inline">x</span>, but we often use <span class="math inline">D</span> in a causal setting).</li>
<li>The variable which changes as a result of the change in <span class="math inline">D</span> is the <strong>outcome</strong>, labelled <span class="math inline">y</span>.</li>
<li>Thus, our causal effect of interest is <span class="math inline">D \rightarrow y</span>.</li>
<li>A third variable which causes both <span class="math inline">D</span> and <span class="math inline">y</span> is called a <strong>confounder</strong> or <strong>confounding variable</strong>, and is often labelled <span class="math inline">w</span> or <span class="math inline">c</span>.</li>
</ul>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://politicalscience.github.io/metrics/">Course Homepage</a></p>
</section>
</section>
<section id="potential-outcomes-and-causal-effects" class="level1">
<h1>2.2: Potential Outcomes and Causal Effects</h1>
<section id="potential-outcomes-framework" class="level3">
<h3 class="anchored" data-anchor-id="potential-outcomes-framework">Potential Outcomes Framework</h3>
<p>A <strong>causal effect</strong> is a change in some feature of the world <span class="math inline">D</span> that directly causes a change in some feature of the world <span class="math inline">y</span>. Causal effects imply the existence of <strong>potential outcomes</strong>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition: Potential Outcomes
</div>
</div>
<div class="callout-body-container callout-body">
<p>Imagine that there are 2 parallel worlds that are exactly the same, and there is one unit/individual <span class="math inline">i</span> who exists in both worlds.</p>
<p>Then, in one of the two worlds, unit <span class="math inline">i</span> gets the treatment <span class="math inline">D</span>, which causes a change in the outcome <span class="math inline">y</span>. In the other world, unit <span class="math inline">i</span> does not get the treatment <span class="math inline">D</span>, so there is no change in outcome <span class="math inline">y</span>.</p>
<p>Since these 2 parallel worlds are identical <strong>except</strong> for the fact one world gets the treatment <span class="math inline">D</span> and the other does not, the difference in the world’s <span class="math inline">y</span> outcomes can only be the effect of treatment <span class="math inline">D</span>.</p>
<p>The difference in the two world’s outcome <span class="math inline">y</span> is thus the <strong>causal effect</strong> of <span class="math inline">D</span> on <span class="math inline">y</span>.</p>
</div>
</div>
<p><br></p>
<p>Let us represent these two parallel worlds more formally:</p>
<ul>
<li>The parallel world where unit <span class="math inline">i</span> gets the treatment will be called the <strong>treatment state</strong>, and will take a value of <span class="math inline">D=1</span>.</li>
<li>The parallel world where unit <span class="math inline">i</span> does not get the treatment will be called the <strong>control state</strong>, and will take a value of <span class="math inline">D=0</span>.</li>
</ul>
<p>Thus, the outcomes of unit <span class="math inline">i</span> in these 2 parallel worlds can be notated as <span class="math inline">y_{Di}</span>, where <span class="math inline">D</span> is the state of the world.</p>
<ul>
<li>In the <strong>treatment state</strong> <span class="math inline">D=1</span>, we will label the outcome of unit <span class="math inline">i</span> as <span class="math inline">y_{1i}</span></li>
<li>In the <strong>control state</strong> <span class="math inline">D=0</span>, we will label the outcome of unit <span class="math inline">i</span> as <span class="math inline">y_{0i}</span>.</li>
</ul>
<p><br></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: Democracy and Economic Growth
</div>
</div>
<div class="callout-body-container callout-body">
<p>Let us say we want to find if democracy causes better economic growth. Democracy is our treatment <span class="math inline">D</span>, and economic growth is our outcome <span class="math inline">y</span>.</p>
<p>Country <span class="math inline">i</span> (for simplicity, let us say Canada) is one of the units. There are two parallel worlds:</p>
<ul>
<li>In one parallel world, Canada is in the <strong>treatment state</strong> <span class="math inline">D=1</span>, meaning it is a democracy. Its outcome in this world would be its economic growth <span class="math inline">y_{1i}</span>.</li>
<li>In the other parallel world, Canada is in the <strong>control state</strong> <span class="math inline">D=0</span>, meaning it is not a democracy. Its outcome in this world would be its economic growth <span class="math inline">y_{0i}</span>.</li>
</ul>
</div>
</div>
<p><br></p>
</section>
<section id="causal-effects" class="level3">
<h3 class="anchored" data-anchor-id="causal-effects">Causal Effects</h3>
<p>As we mentioned in the potential outcomes framework, the difference in the outcomes in the two parallel worlds must be the causal effect of <span class="math inline">D</span>, since everything else in the parallel worlds are identical.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition: Individual Causal Effects
</div>
</div>
<div class="callout-body-container callout-body">
<p>Thus, the individual causal effect of <span class="math inline">D</span> on unit <span class="math inline">i</span> is the difference of outcomes <span class="math inline">y</span> in the treatment state and the control state. Mathematically:</p>
<p><span class="math display">
\tau_i = y_{1i} - y_{0i}
</span></p>
</div>
</div>
<p>Thus, the treatment <span class="math inline">D</span> will have <span class="math inline">\tau_i</span> effect on outcome <span class="math inline">y</span> for unit <span class="math inline">i</span></p>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://politicalscience.github.io/metrics/">Course Homepage</a></p>
</section>
</section>
<section id="observed-outcomes-and-the-stable-unit-treatment-value-assumption" class="level1">
<h1>2.3: Observed Outcomes and the Stable Unit Treatment Value Assumption</h1>
<section id="observed-outcomes" class="level3">
<h3 class="anchored" data-anchor-id="observed-outcomes">Observed Outcomes</h3>
<p>Of course, in real life, we do not have parallel worlds. We only observe one of these parallel worlds.</p>
<p>For example, in the real world, we know Canada is a democracy. We do not observe the parallel world that Canada is a dictatorship. Thus, we also only have one of Canada’s potential outcomes, while the other is unobservable.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition: Observed Outcomes
</div>
</div>
<div class="callout-body-container callout-body">
<p>Observed outcomes are a subset of potential outcomes that actually come true in the real world. Observed outcomes are given by the formula:</p>
<p><span class="math display">
y_i = D_i \times y_{1i} + (1-D_i) \times y_{0i}
</span></p>
<ul>
<li>Where <span class="math inline">y_i</span> is the observed outcome, <span class="math inline">y_{1i}</span> is the potential outcome of the treatment state, and <span class="math inline">y_{0i}</span> is the potential outcome of the control state.</li>
<li>Where <span class="math inline">D_i</span> represents what state unit <span class="math inline">i</span> is in, where <span class="math inline">D_i = 1</span> indicates unit <span class="math inline">i</span> is in the treatment state, and <span class="math inline">D_i = 0</span> indicates unit <span class="math inline">i</span> is in the control state.</li>
</ul>
</div>
</div>
<p>This formula might seem unintuitive. But we can plug in values of <span class="math inline">D_i</span> to understand what this formula means.</p>
<p>What if unit <span class="math inline">i</span> is in the treatment state, <span class="math inline">D_i = 1</span>. Let us plug in <span class="math inline">D_i = 1</span> into the equation:</p>
<p><span class="math display">
\begin{split}
y_i &amp; = D_i \times y_{1i} + (1-D_i) \times y_{0i} \\
y_i &amp; = 1 \times y_{1i} + (1-1) \times y_{0i} \\
y_i &amp; = y_{1i}
\end{split}
</span></p>
<p>Thus, the observed outcome when unit <span class="math inline">i</span> is in the treatment state is <span class="math inline">y_{1i}</span>, which makes sense, since that is the potential outcome of the treatment state.</p>
<p><br></p>
<p>Similarly, what if unit <span class="math inline">i</span> is in the control state <span class="math inline">D_i = 0</span>. Let us plug in <span class="math inline">D_i = 0</span> into the equation:</p>
<p><span class="math display">
\begin{split}
y_i &amp; = D_i \times y_{1i} + (1-D_i) \times y_{0i} \\
y_i &amp; = 0 \times y_{1i} + (1-0) \times y_{0i} \\
y_i &amp; = y_{0i}
\end{split}
</span></p>
<p>Thus, the observed outcome when unit <span class="math inline">i</span> is in the control state is <span class="math inline">y_{0i}</span>, which makes sense, since that is the potential outcome of the control state.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition: Counterfactuals
</div>
</div>
<div class="callout-body-container callout-body">
<p>A counterfactual is the potential outcome that is not observed. For example, if in the real world, unit <span class="math inline">i</span> is observed to have received the treatment, then its counterfactual is the world where unit <span class="math inline">i</span> did not receive the treatment.</p>
<p>Counterfactuals are important, because, if we remember, the individual causal effect is <span class="math inline">\tau_i = y_{1i} - y_{0i}</span>, which implies that we must know the counterfactual to find the causal effect of <span class="math inline">D</span> on <span class="math inline">y</span>.</p>
</div>
</div>
<p><br></p>
</section>
<section id="sampling-and-observed-outcomes" class="level3">
<h3 class="anchored" data-anchor-id="sampling-and-observed-outcomes">Sampling and Observed Outcomes</h3>
<p>Sampling is the process of using a subset of a larger population to make claims on the larger population.</p>
<ul>
<li>For example, pollsters do not ask everyone how they will vote - they ask a small <strong>sample</strong> and, if that sample is representative, use that sample to conclude how everyone in the country will vote.</li>
</ul>
<p>We can actually think about sampling in terms of observed outcomes.</p>
<ul>
<li>Our population is all of the potential outcomes covered in <a href="https://politicalscience.github.io/metrics/causal/2.html#potential-outcomes-and-causal-effects">section 2.2</a>.</li>
<li>Our sample is the observed outcomes that are realised in the real world. This is a subset that we are selecting - and we can only use what we observe to try to estimate causal effects on the entire population of potential outcomes.</li>
</ul>
<p>This will become useful when we run hypothesis testing for causal inference in section 2.6 and section 2.7</p>
<p><br></p>
</section>
<section id="stable-unit-treatment-value-observation" class="level3">
<h3 class="anchored" data-anchor-id="stable-unit-treatment-value-observation">Stable Unit Treatment Value Observation</h3>
<p>The stable unit treatment value assumption (SUTVA) is arguably the key assumption of causal inference.</p>
<p>SUTVA states that given two units <span class="math inline">i</span> and <span class="math inline">j</span>, unit <span class="math inline">i</span> is not affected by the treatment assignment of unit <span class="math inline">j</span>. More intuitively, if unit <span class="math inline">j</span> is assigned to treatment, that has no effect on the outcomes of unit <span class="math inline">i</span>.</p>
<p>Why is this important? Well, if unit <span class="math inline">j</span>’s treatment status affects unit <span class="math inline">i</span>, then unit <span class="math inline">i</span> would have more than 2 potential outcomes:</p>
<ul>
<li>This is because unit <span class="math inline">i</span>’s outcomes would now not only depend on itself being assigned to treatment or control, but also unit <span class="math inline">j</span> being assigned to treatment or control.</li>
<li>That means unit <span class="math inline">i</span> now has 4 potential outcomes. If unit <span class="math inline">i</span> is affected by other units other than <span class="math inline">j</span>, this will quickly multiply to an unmanageable number of potential outcomes.</li>
</ul>
<p>Thus, violating this assumption will basically make it impossible to calculate treatment effects.</p>
<p><br></p>
<p>In what situations is SUTVA typically violated?</p>
<ol type="1">
<li>Peer effects that result from contact between units <span class="math inline">i</span> and <span class="math inline">j</span>. For example, if you are testing the treatment of some new curriculum on student educational outcomes, and unit <span class="math inline">j</span> is assigned to treatment, unit <span class="math inline">j</span> might teach their friend unit <span class="math inline">i</span> some new things, even if unit <span class="math inline">i</span> was in the control group.</li>
<li>Dilution/concentration effects that arise from a prevalence of a treatment. The best example is vaccines - if enough people get a vaccine for a disease, even people who do not get the vaccine are safer, since transmission is much more difficult.</li>
</ol>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://politicalscience.github.io/metrics/">Course Homepage</a></p>
</section>
</section>
<section id="causal-estimands" class="level1">
<h1>2.4: Causal Estimands</h1>
<p>We introduced how the individual treatment effect of <span class="math inline">D \rightarrow y</span> for any unit <span class="math inline">i</span> is <span class="math inline">\tau_i = y_{1i} - y_{0i}</span>. However, there is an issue - we do not know the two parallel worlds.</p>
<ul>
<li>As we discussed in <a href="https://politicalscience.github.io/metrics/causal/1.html#observed-outcomes-and-the-stable-unit-treatment-value-assumption">section 1.3</a>, we can only observe one of the two parallel worlds.</li>
</ul>
<p>Thus, we can never actually find (or estimate) the individual treatment effect. We need another <strong>estimand</strong>. An <strong>estimand</strong> is the true value of something in the real world, that we will try to estimate with an estimator.</p>
<p>This course will focus on introducing many new estimators to try to estimate these estimands. However, before we start estimating, we have to know what we are trying to estimate. What are the estimands we can use, if individual treatment effect is not possible?</p>
<p><br></p>
<p>The “key” estimand in causal inference is the Average Treatment Effect:</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition: Average Treatment Effect
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <strong>Average Treatment Effect (ATE)</strong> is the average of all individual treatment effects:</p>
<p><span class="math display">
\text{ATE} \ = \ \mathbb{E}[\tau_i] \ = \ \bar{y}_{1i} - \bar{y}_{0i}
</span></p>
<p>Where the bar over the <span class="math inline">y</span> represents mean.</p>
</div>
</div>
<p>However, the ATE is not the only estimand we are interested in.</p>
<p><br></p>
<p>Sometimes, our treatment variables are continuous. For example, if we want to estimate how GDP affects democratisation, our treatment variable GDP is not binary.</p>
<p>In cases of non-continuous treatment variables, we want to estimate the <strong>average causal effect</strong> (ACE)- the expected change in <span class="math inline">y</span> resulting from a one unit increase in <span class="math inline">D</span>:</p>
<p><span class="math display">
\text{ACE} = \mathbb{E}[y'(D)]
</span></p>
<p>Where <span class="math inline">y'(D)</span> is the derivative of <span class="math inline">y</span> in respect to <span class="math inline">D</span></p>
<p><br></p>
<p>Sometimes, we have reason to expect that the treatment effect may be different accross different categories of units.</p>
<p>For example, maybe we think that a certain educational treatment will benefit women more than men, so the treatment effect will be higher for women than men.</p>
<p>The <strong>Conditional Average Treatment Effect (CATE)</strong> is the treatment effect of units, given they have some other variable <span class="math inline">x</span> value.</p>
<p><span class="math display">
\text{CATE} = \mathbb{E}[ \tau_i | x_i ]
</span></p>
<p><br></p>
<p>We can also estimate the causal effect on only the treatment or control groups.</p>
<p>The <strong>average treatment effect on the treated (ATT)</strong> is the average treatment effect of only units who received the treatment <span class="math inline">D_i = 1</span>:</p>
<p><span class="math display">
\text{ATT} = \mathbb{E} [\tau_i | D_i = 1] = \bar{y}_{1i, \ D_i = 1} - \bar{y}_{0i, \ D_i = 1}
</span></p>
<p>The <strong>average treatment effect on the controls (ATC)</strong> is the average treatment effect of only units who did not receive the treatment <span class="math inline">D_i = 0</span>:</p>
<p><span class="math display">
\text{ATC} = \mathbb{E} [\tau_i|D_i = 0] = \bar{y}_{1i, \ D_i = 0} - \bar{y}_{0i, \ D_i = 0}
</span></p>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://politicalscience.github.io/metrics/">Course Homepage</a></p>
</section>
<section id="properties-of-estimators---unbiasedness-and-consistency" class="level1">
<h1>2.5: Properties of Estimators - Unbiasedness and Consistency</h1>
<p>The above causal estimands are not directly calculable, since we cannot observe both potential outcomes. Thus, we need an <strong>estimator</strong> to estimate the causal estimands.</p>
<p>Estimators have two key properties: unbiasdness and consistency.</p>
<p><br></p>
<section id="unbiasedness" class="level3">
<h3 class="anchored" data-anchor-id="unbiasedness">Unbiasedness</h3>
<p>An estimator is <strong>unbiased</strong> if its estimates <span class="math inline">\hat{\theta}</span> are on average equal to the true estimand <span class="math inline">\theta</span>.</p>
<p><span class="math display">
\mathbb{E}[ \ \hat{\theta} \ ] = \theta
</span></p>
<p>Note: I use <span class="math inline">\theta</span> to represent any possible estimand, including the causal estimands from above.</p>
<p>To better understand unbiasdness, take this example of archery. We have two archers, archer <span class="math inline">A</span> and archer <span class="math inline">B</span>.</p>
<ul>
<li>Both archers are very very accurate - as in they hit the same spot on the target every time they shoot.</li>
<li>Archer <span class="math inline">A</span> gets the bullseye every single time.</li>
<li>However, archer <span class="math inline">B</span>, while very consistently hitting the same spot, for some reason, keeps hitting 5 inches to the right of the bullseye.</li>
</ul>
<p>Thus, archer <span class="math inline">B</span> is biased - he is consistently and systematically hitting the wrong spot on the target. Similarly, if an estimate is consistently off by a certain value, then it is biased.</p>
<p><br></p>
</section>
<section id="consistency" class="level3">
<h3 class="anchored" data-anchor-id="consistency">Consistency</h3>
<p>However, an unbiased estimator is not good enough. Why? Take this example of another archer <span class="math inline">C</span>.</p>
<ul>
<li>Archer <span class="math inline">C</span> has good aim - he is aiming directly at the bullseye.</li>
<li>However, archer <span class="math inline">C</span> is very inconsistent - he first hits a shot 5 inches to the left of the bullseye, then hits a shot 5 inches to the right of the bullseye. He keeps doing both of these things over and over again.</li>
<li>Archer <span class="math inline">C</span> on average is actually hitting the bullseye, since his leftward and rightward errors cancel each other out.</li>
<li>However, archer <span class="math inline">C</span> never actually hits the bullseye on any specific shot.</li>
</ul>
<p>Archer <span class="math inline">C</span> is an example of an unbiased, but very inconsistent estimator. On average, he is getting the right value of the estimate, but he is never that close on any specific estimate.</p>
<ul>
<li>More technically, an inconsistent estimator is one who has high <strong>variance</strong> in their estimates.</li>
</ul>
<p><br></p>
<p>Ideally, <u>we want an estimator that is both <strong>unbiased</strong> and <strong>consistent</strong></u>. This would mean that their average estimates are equal to the true estimand, and that each estimate is relatively close to the true estimand with low variance.</p>
<ul>
<li>So, an archer than on average, hits the bullseye, and is generally not too far off from the bullseye on any sepcific shot.</li>
</ul>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://politicalscience.github.io/metrics/">Course Homepage</a></p>
</section>
</section>
<section id="the-naive-estimator-and-proof-correlation-is-not-causation" class="level1">
<h1>2.6: The Naive Estimator and Proof Correlation is not Causation</h1>
<p>The <strong>naive estimator</strong> is an estimator that only compares the observed outcomes, without any comparison to the counterfactual potential outcomes.</p>
<p>So essentially, we compare the observed treatment group outcomes and the observed control group outcomes:</p>
<p><span class="math display">
\hat{\tau}_{\text{naive}} = \bar{y}_{1i, \ D_i = 1} - \bar{y}_{0i, \ D_i = 0}
</span></p>
<p>This is what many people do when trying to find a causal effect. The naive estimator is also similar to a measure of correlation.</p>
<p><br></p>
<p>However, <u><strong>the naive estimator is a bad idea</strong></u>. Remember, treatment effects are supposed to be comparing the two potential outcomes <u>of the same unit</u>. We are supposed to compare <span class="math inline">y_{1i}</span> to <span class="math inline">y_{0i}</span>.</p>
<ul>
<li>However, the naive estimator does not do that. Instead, it is comparing the observed outcomes of the treatment group versus the different control group.</li>
</ul>
<p>So essentially, it is comparing the potential outcomes of <u>different</u> units.</p>
<ul>
<li>But what is the issue with this?</li>
<li>Well, if you compare the potential outcome of two different units (let us call them <span class="math inline">A</span> and <span class="math inline">B</span>), you are comparing <span class="math inline">y_{1A}</span> and <span class="math inline">y_{1B}</span>.</li>
<li>However, what if units <span class="math inline">A</span> and <span class="math inline">B</span> are different in some way even before the treatment? Their outcomes <span class="math inline">y</span> may differ not due to the treatment <span class="math inline">D</span>, but due to some underlying difference between units <span class="math inline">A</span> and <span class="math inline">B</span>.</li>
<li>Thus, we are introducing some <strong>bias</strong> - the differences between unit <span class="math inline">A</span> and <span class="math inline">B</span> are being included in our causal estimate, when they should not be, since the differences between <span class="math inline">A</span> and <span class="math inline">B</span> may not be due to <span class="math inline">D</span>.</li>
</ul>
<p><br></p>
<p>We can prove this mathematically. We start with the naive estimator:</p>
<p><span class="math display">
\hat{\tau} = \bar{y}_{1i, \ D_i = 1} - \bar{y}_{0i, \ D_i = 0}
</span></p>
<p>Then, we do a little algebra trick - we add a new term to this equation, then subtract that same term. The two new terms thus cancel each other out to 0:</p>
<p><span class="math display">
\hat{\tau} = \bar{y}_{1i, \ D_i = 1} - \bar{y}_{0i, \ D_i = 0} + \bar{y}_{0i, \ D_i = 1} - \bar{y}_{0i, \ D_i = 1}
</span></p>
<p>Now, let us re-arrange this equation:</p>
<p><span class="math display">
\hat{\tau} = \bar{y}_{1i, \ D_i = 1} - \bar{y}_{0i, \ D_i = 1} + \bar{y}_{0i, \ D_i = 1} - \bar{y}_{0i, \ D_i = 0}
</span></p>
<p>We can see the first two terms are equal to the average treatment effect on the treated (ATT). Thus, we can rewrite the naive estimator:</p>
<p><span class="math display">
\hat{\tau} = \text{ATT} + \bar{y}_{0i, \ D_i = 1} - \bar{y}_{0i, \ D_i = 0}
</span></p>
<p>If we look at the final result, we can divide it into two parts:</p>
<ol type="1">
<li>The ATT (see <a href="https://politicalscience.github.io/metrics/causal/1.html#causal-estimands">section 1.4</a>)</li>
<li>The extra bit: <span class="math inline">\bar{y}_{0i, \ D_i = 1} - \bar{y}_{0i, \ D_i = 0}</span>, which we call <strong>selection bias</strong>. Intuitively, it is the difference <u>prior to treatment</u> between the control and treatment groups. This results in our naive estimator being biased.</li>
</ol>
<p>We will go into detail on selection bias in the next section.</p>
<p><br></p>
<hr>
<p><a href="https://politicalscience.github.io/metrics/">Course Homepage</a></p>
</section>
<section id="selection-bias-and-confounding-variables" class="level1">
<h1>2.7: Selection Bias and Confounding Variables</h1>
<section id="selection-bias" class="level3">
<h3 class="anchored" data-anchor-id="selection-bias">Selection Bias</h3>
<p>As we just established, the naive estimator contains <strong>selection bias</strong> <span class="math inline">\bar{y}_{0i, \ D_i = 1} - \bar{y}_{0i, \ D_i = 0}</span>. This is the difference <u>prior to treatment</u> between the control and treatment groups.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: Hospital and Health
</div>
</div>
<div class="callout-body-container callout-body">
<p>For example, if we are measuring the question <em>does going to the hospital make you more healthy</em>, and we simply measured the outcomes of people who went to the hospital and did not go to the hospital, we might see that in general, people who did not go to the hospital are healthier!</p>
<ul>
<li><p>Does this mean that going to the hospital makes you unhealthier? No! It is because more unhealthy people choose to go to the hospital in the first place. Thus, the hospital has generally more unhealthy individuals in it. The hospital might perform miracles on these people, but they are still not as healthy as the healthy people who did not need to go to the hospital.</p></li>
<li><p>The differences between the people who chose to go to the hospital versus the people who did not go to the hospital explains the differences in our outcome, not the actual treatment that the hospital provided.</p></li>
</ul>
</div>
</div>
<p>Thus, selection bias can be thought of as when our treatment and control groups are fundamentally different and unequal prior to treatment.</p>
<ul>
<li>And when we use the naive estimator (or correlation), we pick up this bias in our estimates.</li>
</ul>
<p><br></p>
</section>
<section id="confounding-variables" class="level3">
<h3 class="anchored" data-anchor-id="confounding-variables">Confounding Variables</h3>
<p>Selection bias is caused by confounding variables.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition: Confounding Variable
</div>
</div>
<div class="callout-body-container callout-body">
<p>A <strong>confounder</strong> or <strong>confounding variable</strong> is a variable that is causes differences in the treatment and control groups.</p>
<p>Confounding variables result in selection bias, and are why correlation does not equal causation. In order to accurately calculate causal effects, we need to find some way to eliminate the effect of confounding variables.</p>
</div>
</div>
<p>For example, look at the figure below:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/1-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<p>In this figure, <span class="math inline">D</span> is the treatment, and <span class="math inline">C</span> is the confounding variable that affects whether or not a unit gets the treatment <span class="math inline">D</span> or not.</p>
<p>When we calculate the naive estimate (or correlation), our causal estimate captures both the direct effect <span class="math inline">D \rightarrow Y</span>, but also the effect of <span class="math inline">D \leftrightarrow C \rightarrow O \rightarrow Y</span>, since <span class="math inline">D</span> and <span class="math inline">C</span> are correlated.</p>
<ul>
<li>This second effect <span class="math inline">D \leftrightarrow C \rightarrow O \rightarrow Y</span> is called the <strong>backdoor path</strong>.</li>
</ul>
<p>However, the actual causal effect of treatment <span class="math inline">D</span> on <span class="math inline">Y</span> is only the section of <span class="math inline">D \rightarrow Y</span>, and does not include the backdoor path. So, we need to find some way to only look at <span class="math inline">D \rightarrow Y</span>, and eliminate/partial out the effect of the back door.</p>
<p><br></p>
<p>To make an accurate causal effect estimate, we must get rid of confounding variables, selection bias, and the backdoor path. How do we do this?</p>
<p>There are many many methods to eliminate the effect of confounding variables.</p>
<ul>
<li>The best method is randomisation, which we will cover in the next chapter.</li>
<li>After we cover randomisation, we will cover methods to eliminate confounding variables when randomisation is not possible, including multiple linear regression, instrumental variables, selection on observables, quasi-experimental methods, and many more.</li>
</ul>
<p><br></p>
<hr>
<p><a href="https://politicalscience.github.io/metrics/">Course Homepage</a></p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>