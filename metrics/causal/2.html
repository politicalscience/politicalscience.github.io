<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Chapter 2: Randomised Controlled Trials as the Gold Standard</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="2_files/libs/clipboard/clipboard.min.js"></script>
<script src="2_files/libs/quarto-html/quarto.js"></script>
<script src="2_files/libs/quarto-html/popper.min.js"></script>
<script src="2_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="2_files/libs/quarto-html/anchor.min.js"></script>
<link href="2_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="2_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="2_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="2_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="2_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: true
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body>

<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Chapter 2: Randomised Controlled Trials as the Gold Standard</h1>
            <p class="subtitle lead">Econometric Methods (for Social Scientists)</p>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99">
    <h2 id="toc-title">Chapter 2: Randomised Controlled Trials as the Gold Standard</h2>
   
  <ul class="collapse">
  <li><a href="#random-assignment-and-confounders" id="toc-random-assignment-and-confounders" class="nav-link active" data-scroll-target="#random-assignment-and-confounders">2.1: Random Assignment and Confounders</a></li>
  <li><a href="#difference-in-means-estimator-for-causal-effects" id="toc-difference-in-means-estimator-for-causal-effects" class="nav-link" data-scroll-target="#difference-in-means-estimator-for-causal-effects">2.2: Difference-in-Means Estimator for Causal Effects</a></li>
  <li><a href="#uncertainty-in-estimates-and-standard-errors" id="toc-uncertainty-in-estimates-and-standard-errors" class="nav-link" data-scroll-target="#uncertainty-in-estimates-and-standard-errors">2.3: Uncertainty in Estimates and Standard Errors</a></li>
  <li><a href="#hypothesis-tests-and-causal-inference" id="toc-hypothesis-tests-and-causal-inference" class="nav-link" data-scroll-target="#hypothesis-tests-and-causal-inference">2.4: Hypothesis Tests and Causal Inference</a></li>
  <li><a href="#confidence-intervals-and-plausible-values-of-the-causal-effect" id="toc-confidence-intervals-and-plausible-values-of-the-causal-effect" class="nav-link" data-scroll-target="#confidence-intervals-and-plausible-values-of-the-causal-effect">2.5: Confidence Intervals and Plausible Values of the Causal Effect</a></li>
  <li><a href="#balance-tables-to-verify-the-assumptions-of-randomisation" id="toc-balance-tables-to-verify-the-assumptions-of-randomisation" class="nav-link" data-scroll-target="#balance-tables-to-verify-the-assumptions-of-randomisation">2.6: Balance Tables to Verify the Assumptions of Randomisation</a></li>
  <li><a href="#blocking-and-stratified-experiments" id="toc-blocking-and-stratified-experiments" class="nav-link" data-scroll-target="#blocking-and-stratified-experiments">2.7: Blocking and Stratified Experiments</a></li>
  <li><a href="#validity-and-issues-with-randomised-controlled-trials" id="toc-validity-and-issues-with-randomised-controlled-trials" class="nav-link" data-scroll-target="#validity-and-issues-with-randomised-controlled-trials">2.8: Validity and Issues with Randomised Controlled Trials</a></li>
  <li><a href="#implementation-in-r" id="toc-implementation-in-r" class="nav-link" data-scroll-target="#implementation-in-r">Implementation in R</a>
  <ul class="collapse">
  <li><a href="#difference-in-means-estimator" id="toc-difference-in-means-estimator" class="nav-link" data-scroll-target="#difference-in-means-estimator">Difference-in-Means Estimator</a></li>
  <li><a href="#hypothesis-testing-in-experiments" id="toc-hypothesis-testing-in-experiments" class="nav-link" data-scroll-target="#hypothesis-testing-in-experiments">Hypothesis Testing in Experiments</a></li>
  <li><a href="#confidence-intervals-in-experiments" id="toc-confidence-intervals-in-experiments" class="nav-link" data-scroll-target="#confidence-intervals-in-experiments">Confidence Intervals in Experiments</a></li>
  <li><a href="#balance-tables" id="toc-balance-tables" class="nav-link" data-scroll-target="#balance-tables">Balance Tables</a></li>
  </ul></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>This chapter discusses the best way of estimating causal effects - randomised controlled trials. We will explore why random assignment is so powerful, how to estimate causal effects with the difference-in-means estimator, and the limitations of randomised controlled trials.</p>
<p>Topics: Random Assignment, Difference-in-Means Estimator, Standard Errors, Hypothesis Testing, Confidence Intervals, Stratified Experiments</p>
<p><br></p>
<hr>
<p><a href="https://politicalscience.github.io/metrics/">Course Homepage</a></p>
<section id="random-assignment-and-confounders" class="level1">
<h1>2.1: Random Assignment and Confounders</h1>
<p>The <strong>assignment mechanism</strong> is how we decide which observations receive treatment <span class="math inline">D</span>.</p>
<p>In <a href="https://politicalscience.github.io/metrics/causal/1.html#selection-bias-and-confounding-variables">section 1.6</a>, we discussed how confounder <span class="math inline">C</span> affects which observations get the treatment, which introduces selection bias.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/1-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<p>We can address this confounder <span class="math inline">C</span> and eliminate the backdoor path <span class="math inline">D \leftrightarrow C \rightarrow O \rightarrow Y</span> by randomly assigning units into either treatment or control. With random assignment, the randomness determines who gets the treatment, not confounder <span class="math inline">C</span>:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/2-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<p>With random assignment mechanism <span class="math inline">R</span>, now units are assigned to control randomly, not based on the confounder <span class="math inline">C</span>. Thus, <span class="math inline">C</span> and <span class="math inline">D</span> should no longer be correlated, thus removing the backdoor effect, selection bias, and the influence of confounder <span class="math inline">C</span>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition: Random Assignment
</div>
</div>
<div class="callout-body-container callout-body">
<p>With random assignment ,selection bias and the influence of confounder <span class="math inline">C</span> is eliminated. Thus, the control group and treatment group should be similar, as every observation has an equal chance of being selected into either group.</p>
<p>If the control and treatment groups are similar, the potential outcomes should be independent of treatment and control groups:</p>
<p><span class="math display">
\bar{y}_{1i, \ D_i = 1} \approx \bar{y}_{1i, \ D_i = 0} \approx \bar{y}_{1i} \quad \text{and} \quad \bar{y}_{0i, \ D_i = 1} \approx \bar{y}_{0i, \ D_i = 0} \approx \bar{y}_{0i}
</span></p>
</div>
</div>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://politicalscience.github.io/metrics/">Course Homepage</a></p>
</section>
<section id="difference-in-means-estimator-for-causal-effects" class="level1">
<h1>2.2: Difference-in-Means Estimator for Causal Effects</h1>
<p>Since random assignment removes the effect of confounders, that means there is no more selection bias. Thus, we can use the naive estimator (now called the difference-in-means estimator) to estimate the causal effect.</p>
<p>Let us show this mathematically. Recall the naive estimator:</p>
<p><span class="math display">
\hat{\tau}_{\text{naive}} = \bar{y}_{1i, \ D_i = 1} - \bar{y}_{0i, \ D_i = 0}
</span></p>
<p>Given the assumption of randomisation, we established in the last section, we know:</p>
<p><span class="math display">
\bar{y}_{1i, \ D_i = 1} \approx \bar{y}_{1i, \ D_i = 0} \approx \bar{y}_{1i} \quad \text{and} \quad \bar{y}_{0i, \ D_i = 1} \approx \bar{y}_{0i, \ D_i = 0} \approx \bar{y}_{0i}
</span></p>
<p>Thus, we know the following is true:</p>
<p><span class="math display">
\hat{\tau}_{\text{naive}} = \bar{y}_{1i, \ D_i = 1} - \bar{y}_{0i, \ D_i = 0} \quad \approx \quad \hat{\tau}_{ATE} = \bar{y}_{1i} - \bar{y}_{0i}
</span></p>
<p>Thus, our naive estimator (now called the difference in means estimator) estimates the average treatment effect of <span class="math inline">D</span> on <span class="math inline">y</span>.</p>
<p><br></p>
<p>We can rewrite this equation in a nicer, easier to read format:</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition: Difference-in-Means Estimator
</div>
</div>
<div class="callout-body-container callout-body">
<p>The estimate of the average treatment effect of a randomised controlled trial is:</p>
<p><span class="math display">
\hat{\tau}_{ATE} = \bar{y}_t - \bar{y}_c
</span></p>
<p>Where <span class="math inline">\bar{y}_t</span> is the average <span class="math inline">y</span> value in the treatment group, and <span class="math inline">\bar{y}_c</span> is the average <span class="math inline">y</span> value in the control group.</p>
<p>Thus, the causal effect of <span class="math inline">D</span> on <span class="math inline">y</span> is simply the <strong>difference-in-means</strong> of the two groups.</p>
</div>
</div>
<p>Or in other words, to calculate the average treatment effect of a randomised experiment, we:</p>
<ol type="1">
<li>Calculate <span class="math inline">\bar y_t</span>, which is done by finding the average <span class="math inline">y</span> value in the treatment group</li>
<li>Calculate <span class="math inline">\bar{y}_c</span>, which is done by finding the average <span class="math inline">y</span> value in the control group</li>
<li>Find the difference <span class="math inline">\bar{y}_t - \bar{y}_c</span> and we have our estimate of the average treatment effect.</li>
</ol>
<p><br></p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Interpretation Warning!
</div>
</div>
<div class="callout-body-container callout-body">
<p>For this estimate of the ATE to be true, there must be random assignment of treatment, and the treatment and control groups must be similar to each other on all confounding variables.</p>
</div>
</div>
<p>If this assumption is violated (either due to lack of random assignment, or failure of randomisation), we can no longer estimate the causal effects with the difference-in-means estimator.</p>
<ul>
<li>This is because if the control and treatment groups are not similar to each other on all confounders, there is the possibility of selection bias in our difference-in-means estimator.</li>
</ul>
<p>Finally, note that we can also use a different estimator, the OLS estimator (with simple linear regression), to get the same final estimate. We will discuss this in chapter 3.</p>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://politicalscience.github.io/metrics/">Course Homepage</a></p>
</section>
<section id="uncertainty-in-estimates-and-standard-errors" class="level1">
<h1>2.3: Uncertainty in Estimates and Standard Errors</h1>
<section id="uncertainty-in-our-estimates" class="level3">
<h3 class="anchored" data-anchor-id="uncertainty-in-our-estimates">Uncertainty in our Estimates</h3>
<p>Remember how we randomly assigned units to treatment or control?</p>
<ul>
<li>What if we ran the experiment again?</li>
<li>The treatment and control groups would very likely not be exactly the same, and thus, we would get a slightly different causal effect.</li>
</ul>
<p>Thus, we have some uncertainty with our causal estimate - re-running the experiment might result in a different answer. The ATE we have calculated is only our specific sample average treatment effect (SATE), often notated <span class="math inline">\hat{\tau}_{ATE}</span> or <span class="math inline">\widehat{ATE}</span>.</p>
<ul>
<li>Why sample? Well, through random assignment, you are basically “randomly sampling” potential outcomes - since randomly choosing one unit to be in treatment/control means not seeing the other counterfactual potential outcome.</li>
</ul>
<p>Thus, we need some mechanism to account for sampling variability and how rerunning the experiment might result in different results. We do this with sampling distributions and standard errors.</p>
<p><br></p>
</section>
<section id="sampling-distribution" class="level3">
<h3 class="anchored" data-anchor-id="sampling-distribution">Sampling Distribution</h3>
<p>Imagine that we take a sample from a population (or some random assignment mechanism). Then, we find the average treatment effect of the sample <span class="math inline">\hat{\tau}_{ATE}</span>.</p>
<p>That is a sample estimate, which is often notated <span class="math inline">\hat{\theta}</span>. (I use <span class="math inline">\hat{\theta}</span>, since this idea of uncertainty can be applied to any estimate, not just average treatment effect).</p>
<p>Then, let us take another sample from the same population (or do another random assignment), and find the sample estimate. This will be slightly different than the first sample, since we are randomly sampling. That is another sample estimate.</p>
<p>We keep taking samples from the same population (more random assignments), and getting more and more sample estimates.</p>
<p><br></p>
<p>Now, let us plot all our sample estimates <span class="math inline">\hat{\theta}</span> into a histogram or density plot. The <span class="math inline">x</span> axis labels all the possible sample estimates <span class="math inline">\hat{\theta}</span> we have gotten above, and the <span class="math inline">y</span> axis is how frequently a specific sample estimate occurs.</p>
<p>The result is a distribution, just like a random variable distribution. That distribution is the <strong>sampling distribution</strong>.</p>
<p>According to c<strong>entral limit theorem</strong>, the sampling distribution approximates that of a normal distribu- tion (or t-distribution if our sample size is small). We know that a normal distribution is defined by two parameters - mean and variance.</p>
<p><br></p>
</section>
<section id="standard-errors" class="level3">
<h3 class="anchored" data-anchor-id="standard-errors">Standard Errors</h3>
<p>Our sampling distribution has a variance, which is basically how spread out the variable is. Variance for a variable <span class="math inline">x</span> is defined as:</p>
<p><span class="math display">
Var(x) = \mathbb{E}[(x_i -\bar{x})^2] = \sigma^2
</span></p>
<p>Standard deviation is the square root of variance.</p>
<p><span class="math display">
sd(x) = \sqrt{Var(x)} = \sigma
</span></p>
<p>These formulas are divided by <span class="math inline">\sqrt{n}</span> when we consider the variability of a sample average.</p>
<p><span class="math display">
sd(\hat{x}) = \frac{\sigma}{\sqrt{n}} = \frac{\sqrt{\mathbb{E}[(x_i - \bar{x})^2]}}{\sqrt{n}}
</span></p>
<p>The standard deviation of our sampling distribution is called the <strong>standard error</strong> of our estimate. Our sampling distribution of <span class="math inline">\hat{\tau}</span>, if we remember, is a difference-in-means.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition: Standard Error for Difference in Means
</div>
</div>
<div class="callout-body-container callout-body">
<p>The standard error is the standard deviation of the sampling distribution. It is often notated <span class="math inline">se(\hat{\theta})</span>.</p>
<p>The standard error for a difference-in-means is as follows:</p>
<p><span class="math display">
\widehat{se}(\hat{\tau}) = \sqrt{ \frac{\sigma_t}{n_t} + \frac{\sigma_c}{n_c} } = \sqrt{ \frac{\mathbb{E}[(y_i - \bar{y})^2 | D_i = 1]}{n_t} + \frac{\mathbb{E}[(y_i - \bar{y})^2 | D_i = 0]}{n_c}}
</span></p>
<p>Where <span class="math inline">n_t</span> is the number of observations in the treatment group, <span class="math inline">n_c</span> is the number of observations in the control group.</p>
</div>
</div>
<p>This standard error tells us the preciseness of our estimates - how much variability is there in our estimates given the random sampling uncertainty.</p>
<ul>
<li>We will use the standard error to test if our causal estimates are truly a result of a causal relationship, or just a product of random chance.</li>
</ul>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://politicalscience.github.io/metrics/">Course Homepage</a></p>
</section>
</section>
<section id="hypothesis-tests-and-causal-inference" class="level1">
<h1>2.4: Hypothesis Tests and Causal Inference</h1>
<section id="intuition-of-hypothesis-tests" class="level3">
<h3 class="anchored" data-anchor-id="intuition-of-hypothesis-tests">Intuition of Hypothesis Tests</h3>
<p>We know there is some uncertainty with our sample estimate, as defined by the standard error. So, how do we know if we actually have a causal effect with this uncertainty?</p>
<p>What we do is hypothesis testing: a way to test, given a certain level of uncertainty, whether or not we believe there is a causal effect.</p>
<p>We start off with the status-quo “old theory”, and try to disprove it.</p>
<ul>
<li>This is called the <strong>null hypothesis</strong>, typically notated <span class="math inline">H_0</span>.</li>
<li>For causal inference, our null hypothesis is typically that <em>there is no causal effect of</em> <span class="math inline">D</span> on <span class="math inline">y</span>. We notate this as <span class="math inline">H_0 : \theta = 0</span>.</li>
</ul>
<p>The new theory we are trying to prove is called the <strong>alternate hypothesis</strong>.</p>
<ul>
<li>For causal inference, our alternate hypothesis is typically that <em>there is a causal effect of</em> <span class="math inline">D</span> on <span class="math inline">y</span>. We notate this as <span class="math inline">H_1 : \theta ≠ 0</span>.</li>
</ul>
<p><u>We assume that the null hypothesis is true, unless we are 95% confident that we can reject the null hypothesis, and only then, can we accept the alternative hypothesis.</u></p>
<p><br></p>
</section>
<section id="conducting-a-hypothesis-test" class="level3">
<h3 class="anchored" data-anchor-id="conducting-a-hypothesis-test">Conducting a Hypothesis Test</h3>
<p>We start a hypothesis test by notating our hypotheses:</p>
<p><span class="math display">
H_0 : \theta =0 \quad \text{and} \quad H_1: \theta ≠ 0
</span></p>
<p>Next, we have to find a t-test statistic.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition: T-test Statistic
</div>
</div>
<div class="callout-body-container callout-body">
<p>The t-test statistic tells us how far our estimate <span class="math inline">\hat{\theta}</span> is from the null hypothesis value of <span class="math inline">\theta_0 = 0</span>. This distance is expressed in terms of standard errors of the estimate.</p>
<p><span class="math display">
t= \frac{\hat{\theta} - \theta_0}{\widehat{se}(\hat{\theta})}
</span></p>
<p>Note, since <span class="math inline">\theta_0 = 0</span>, we technically do not need it in the equation. However, sometimes (very rarely), you may have a reason to test a different null hypothesis, so then you would plug in a different value for <span class="math inline">\theta_0</span>.</p>
</div>
</div>
<p><br></p>
<p>After we have a test statistic, we need to consult a t-distribution.</p>
<ul>
<li>For a difference-in-means estimator, we should consult the t-distribution with <span class="math inline">n-2</span> degrees of freedom (degrees of freedom are the sole parameter of the t-distribution).</li>
</ul>
<p>Once we have this t-distribution, start from the centre of the t-distribution, and go <em>t-test-statistic</em> number of standard deviations away from the centre towards both directions.</p>
<p>Then, at the point we have ended up, calculate the probability (area under the curve) of a t-test statistic equal or even more extreme could occur (we will not do this manually, the computer will do this). The figure below shows this probability:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/2-2.jpeg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:50.0%"></p>
</figure>
</div>
<p>The shaded area is the probability of a t-test statistic equal to or even more extreme could occur, given the null hypothesis is true. This is the p-value.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition: P-Value
</div>
</div>
<div class="callout-body-container callout-body">
<p>The p-value is the probability of a t-test statistic equal to or even more extreme could occur, given the null hypothesis is true.</p>
<p>If this is less than 0.05 (5%), that means the null hypothesis has a very low chance of being true, so we reject the null hypothesis as no longer true.</p>
<ul>
<li><p>So, if the p-value is above 0.05, there is a above 5% chance that the null hypothesis is true. This is too high for our liking, so we cannot reject the null hypothesis, and we cannot conclude any causal effect of <span class="math inline">D</span> on <span class="math inline">y</span>.</p></li>
<li><p>If the p-value is less than 0.05, there is less than a 5% chance that the null hypothesis is true. In econometrics, we thus reject the null hypothesis, and conclude that there is a causal effect of <span class="math inline">D</span> on <span class="math inline">y</span>.</p></li>
</ul>
<p><u>So very simply, if the p-value is less than 0.05, we can conclude that there is a causal effect of <span class="math inline">D</span> on <span class="math inline">y</span>. If not, we cannot conclude this.</u></p>
</div>
</div>
<p>Thus, the hypothesis test allows us to test if, under uncertainty due to randomisation, if we actually have a causal effect of <span class="math inline">D</span> on <span class="math inline">y</span>.</p>
<p><br></p>
</section>
<section id="types-of-errors" class="level3">
<h3 class="anchored" data-anchor-id="types-of-errors">Types of Errors</h3>
<p>Of course, with 95% confidence, there is a chance we incorrectly conclude a causal effect. These are called errors. There are two types of errors.</p>
<ol type="1">
<li><strong>Type I error</strong>, also called a <strong>false positive</strong>. This occurs when we reject the null hypothesis, even though the null hypothesis is actually true.</li>
<li><strong>Type II error</strong>, also called a <strong>false negative</strong>. This occurs when we fail to reject the null hypothesis, even though the null hypothesis is actually false.</li>
</ol>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://politicalscience.github.io/metrics/">Course Homepage</a></p>
</section>
</section>
<section id="confidence-intervals-and-plausible-values-of-the-causal-effect" class="level1">
<h1>2.5: Confidence Intervals and Plausible Values of the Causal Effect</h1>
<p>With a hypothesis test, we have either concluded that we have, or do not have, a causal relationship between <span class="math inline">D</span> and <span class="math inline">y</span>.</p>
<p>However, whether a causal relationship exists or not is not the only thing we care about. We also care about the <strong>size/magnitude</strong> of the causal relationship.</p>
<ul>
<li>After all, if <span class="math inline">D</span> causes <span class="math inline">y</span> to increase by 0.000000000001 units, who actually cares? The causal effect might as well not exist.</li>
</ul>
<p>We have a causal estimate <span class="math inline">\hat{\theta} = \hat{\tau}_{ATE}</span> already. However, the issue, as we described in section 2.3, is that if we run another random assignment, we will get a slightly different causal estimate.</p>
<p>So how do we account for this issue? We can do this with <strong>confidence intervals</strong>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition: Confidence Intervals
</div>
</div>
<div class="callout-body-container callout-body">
<p>Confidence Intervals are intervals of plausible true <span class="math inline">\theta</span> values given our sample estimate <span class="math inline">\hat{\theta}</span>. We create this interval by adding “buffer” to each side of our sample estimate.</p>
<p>The lower and upper bounds of this 95% confidence interval is:</p>
<p><span class="math display">
\hat{\theta} ± 1.96 \widehat{se}(\hat{\theta})
</span></p>
<p>The reason for the 1.96 is that in a normal distribution, 1.96 standard deviations above and below the mean contains 95% of the area under the distribution.</p>
<ul>
<li>This can slightly change if our sample size is less than 30, where we will use a t-distribution instead. The computer can help us calculate this.</li>
</ul>
<p>The 95% confidence interval means that, if we were to run random sample after random sample, 95% of the confidence intervals generated from each sample’s estimates, would contain the true value of <span class="math inline">\theta</span>.</p>
</div>
</div>
<p>The “key” thing about confidence intervals is if the interval contains the number 0. This is because if 0 is in the interval, that means 0 is a plausible value of <span class="math inline">\theta</span>.</p>
<ul>
<li>Remember, when <span class="math inline">\theta = 0</span>, that means there is no causal effect of <span class="math inline">D</span> on <span class="math inline">y</span>.</li>
<li>That means if 0 is included in the interval, we cannot conclude a causal relationship exists between <span class="math inline">D</span> and <span class="math inline">y</span>.</li>
<li>However, we do not need to worry too much about this, since a hypothesis test and a 95% confidence interval give the same results. If a hypothesis test fails to reject the null, 0 will be included in the confidence interval. If a hypothesis test rejects the null, 0 will not be included in the confidence interval.</li>
</ul>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://politicalscience.github.io/metrics/">Course Homepage</a></p>
</section>
<section id="balance-tables-to-verify-the-assumptions-of-randomisation" class="level1">
<h1>2.6: Balance Tables to Verify the Assumptions of Randomisation</h1>
<p>If the treatment and control groups are not similar (in regard to key confounding variable values), our difference-in-means estimator will be biased with selection bias.</p>
<p>Why is this? Well, if our treatment and control groups are not similar, then the following assumptions will not be met, which are critical in eliminating selection bias:</p>
<p><span class="math display">
\bar{y}_{1i, \ D_i = 1} \approx \bar{y}_{1i, \ D_i = 0} \approx \bar{y}_{1i} \quad \text{and} \quad \bar{y}_{0i, \ D_i = 1} \approx \bar{y}_{0i, \ D_i = 0} \approx \bar{y}_{0i}
</span></p>
<p>Thus, we need to be confident this assumption is met.</p>
<p>For researchers, this is especially important, since they need to show that their results are valid. Thus researchers will often show a <strong>balance table</strong> before or after their estimation process.</p>
<p>A balance table is essentially a table that shows the average difference in values of confounders in both treatment and control groups. For example, below is a balance table:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/2-3.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
<p>The key row to look at is the <em>treatment-control</em> row.</p>
<ul>
<li>The numbers not in parentheses the difference between treatment and control for the corresponding confounder.</li>
<li>The numbers in parentheses are the standard errors of the estimated difference.</li>
<li>Stars (see legend below the table) show significance of a t-test (we will discuss this in the next section).</li>
</ul>
<p>If no treatment-control for key confounders is significantly different (no stars), then randomisation has suceeded, and indeed, our control and treatment group are similar.</p>
<ul>
<li>In the balance table above, there are no stars in the <em>treatment-control</em> row, so our treatment and control groups are similar to each other, and our assumptions are likely to be met.</li>
</ul>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://politicalscience.github.io/metrics/">Course Homepage</a></p>
</section>
<section id="blocking-and-stratified-experiments" class="level1">
<h1>2.7: Blocking and Stratified Experiments</h1>
<p>Blocking, also called stratified experiments, is an extension of randomised experiments to ensure that randomisation does not fail.</p>
<p>Imagine that you have four units in your experiment that you have to assign to treatment/control.</p>
<ul>
<li>Their pre-treatment outcomes are <span class="math inline">y_{0i} = \{2,2,8,8\}</span>.</li>
<li>This means you have a <span class="math inline">1/3</span> chance of ending up with the random assignment of <span class="math inline">\{2,2\}</span> in one group and <span class="math inline">\{8,8\}</span> in another group.</li>
<li>That would not be good - since clearly the treatment and control groups in that situation would be very different from each other, introducing selection bias.</li>
</ul>
<p><br></p>
<p>With <strong>blocking/stratified experiments</strong>, we can prevent this from happening.</p>
<p>The procedure is as follows:</p>
<ol type="1">
<li>Before randomisation, separate your sample of <span class="math inline">N</span> units into <span class="math inline">J</span> subgroups</li>
<li>Within each subgroup, randomly assign units to treatment and control group (essentially, smaller randomised experiments within a bigger experiment).</li>
</ol>
<p><br></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example of Blocking
</div>
</div>
<div class="callout-body-container callout-body">
<p>With out previous example of pre-treatment outcomes being <span class="math inline">y_{0i} = \{2,2,8,8\}</span>, we could divide these observations into <span class="math inline">J=2</span> subgroups.</p>
<ol type="1">
<li>Subgroup 1 would be <span class="math inline">\{2, 2\}</span></li>
<li>Subgroup 2 would be <span class="math inline">\{8, 8\}</span></li>
</ol>
<p>Then, within each subgroup, randomly assign one observation to control, and the other to treatment.</p>
<p>Thus, we are guaranteed to get at least one unit from each subgroup into both our treatment and control groups, minimising the chance randomisation fails.</p>
</div>
</div>
<p><br></p>
<p>To estimate our effects for blocking experiments, we will have to take the weighted average of each subgroup’s average treatment effect (ATE), with the weights being the proportion of units each group accounts for:</p>
<p><span class="math display">
\tau_{ATE} = \sum\limits_{j=1}^J \frac{N_j}{N}\tau_j
</span></p>
<p>Where <span class="math inline">N</span> is the total number of observations, <span class="math inline">J</span> is the total number of subgroups, <span class="math inline">j</span> is one of the subgroups, <span class="math inline">N_j</span> is the number of units within subgroup <span class="math inline">j</span>, and <span class="math inline">\tau_j</span> is the ATE of subgroup <span class="math inline">j</span>.</p>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://politicalscience.github.io/metrics/">Course Homepage</a></p>
</section>
<section id="validity-and-issues-with-randomised-controlled-trials" class="level1">
<h1>2.8: Validity and Issues with Randomised Controlled Trials</h1>
<p>Randomisation, when it works, is magical - it can help us obtain the best estimates of causal effects that are possible.</p>
<p>But, randomised controlled trials do have several issues that can affect our validity of our estimates and conclusions:</p>
<ol type="1">
<li><strong>Failure of randomisation</strong>: if for some reason, randomisation does not result in control and treatment groups being similar, we cannot accurately estimate the average treatment effect. Blocking should help us deal with this, but it is still possible for randomisation to fail.</li>
<li><strong>Non-Compliance</strong>: Sometimes, despite assigning certain units to treatment or control, the units do not comply and do the opposite (i.e.&nbsp;people assigned to control still take the treatment). This is a huge issue since researchers are not gods - we cannot force people to take treatment. The biggest threat non-compliance creates is that perhaps, a confounder is causing certain units to be more likely to not comply. We will deal with this issue in the later parts of this book with Instrumental Variables.</li>
<li><strong>Attrition</strong>: sometimes, it is not possible to measure the outcomes of some people in a study, either due to people moving away, passing away, or refusing to answer surveys or have their measurements be taken. This once again is an issue - since perhaps a confounding variable is causing this issue.</li>
</ol>
<p><br></p>
<p>However, the biggest issue with randomised controlled trials is the impracticality and infeasability of them in many situations, especially in social science research.</p>
<ul>
<li>For example, let us say you want to run an experiment on how democracy affects economic growth.</li>
<li>It is nearly impossible to randomly assign countries to be a democracy. First, if you assign, for example, Russia to be a democracy, you have no power to make them actually follow through with your study. Second, there are ethical concerns about randomly allocating millions to democracy or autocracy.</li>
</ul>
<p>Another major issue is that even when experiments are theoretically feasible, they can be too expensive to implement. Randomised Controlled Trials are extremely expensive even when they are possible to run.</p>
<p><br></p>
<p>Thus, we will need to introduce ways to address for confounders and estimate causal effects for the vast majority of cases where we will not be able to run a randomised controlled trial.</p>
<p>The rest of the part 1 of this course focuses on these techniques. A brief overview of them:</p>
<ul>
<li><p><strong>Simple Linear Regression</strong> will not be of much use for this, as it typically only is feasible in ideal random situations, however, it is the core that many further methods build on, and can help us explore continuous treatment variables.</p></li>
<li><p><strong>Multiple Linear Regression</strong>, in theory, can control for confounding variables. However, the limitation of this is that for an accurate estimation, all possible confounding variables (including unobservable or unmeasureable) confounders have to be included to prevent bias, which is very infeasible most of the time.</p></li>
<li><p><strong>Instrumental Variables Estimator</strong>, in theory, can deal with both non-compliance and confounders, however, there are also drawbacks to this method that we will cover later.</p></li>
<li><p>Q<strong>uasi-experimental methods</strong>, like regression discontinuity and differences-in- differences are the most popular methods of causal inference today, and can deal with many of the weaknesses of other approaches.</p></li>
<li><p><strong>Maximum Likelihood Estimation</strong> deals better than regression with binary outcome variables in some situations, but like regression, all possible confounders have to be included to prevent bias, which is very infeasible most of the time.</p></li>
<li><p><strong>Selection on Observables</strong> methods including matching, subclassification, and weighting, are excellent in specific situations, but fail to deal with unobservable confounders.</p></li>
</ul>
<p><br></p>
<p><br></p>
<hr>
<p><a href="https://politicalscience.github.io/metrics/">Course Homepage</a></p>
</section>
<section id="implementation-in-r" class="level1">
<h1>Implementation in R</h1>
<p>The packages we will need for this are:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(fixest)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(texreg)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br></p>
<section id="difference-in-means-estimator" class="level2">
<h2 class="anchored" data-anchor-id="difference-in-means-estimator">Difference-in-Means Estimator</h2>
<p>There are two ways to estimate the difference in means.</p>
<p>First, we can follow the mathematical formula <span class="math inline">\hat{\tau}_{ATE} = \bar{y}_t - \bar{y}_c</span> by finding the means of the treatment and control group, then finding the difference:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># group by treatment (1 or 0), find mean y</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>ate <span class="ot">&lt;-</span> mydata <span class="sc">%&gt;%</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(treatment) <span class="sc">%&gt;%</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">mean =</span> <span class="fu">mean</span>(y, <span class="at">na.rm =</span> <span class="cn">TRUE</span>), <span class="at">.groups =</span> <span class="st">'drop'</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># that creates a tibble, 1st col is treated status, 2nd col is mean.</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 1st row is treated = 0, 2nd row is treated = 1</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co">#difference</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>ate[<span class="dv">2</span>,<span class="dv">2</span>] <span class="sc">-</span> ate[<span class="dv">1</span>,<span class="dv">2</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For example:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>ate <span class="ot">&lt;-</span> dta <span class="sc">%&gt;%</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(treat_invite) <span class="sc">%&gt;%</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">mean =</span> <span class="fu">mean</span>(pct_missing, <span class="at">na.rm =</span> <span class="cn">TRUE</span>), <span class="at">.groups =</span> <span class="st">'drop'</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>ate[<span class="dv">2</span>,<span class="dv">2</span>] <span class="sc">-</span> ate[<span class="dv">1</span>,<span class="dv">2</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         mean
1 -0.02314737</code></pre>
</div>
</div>
<p><br></p>
<p>Alternatively, we can use regression to estimate the difference-in-means estimator (which will be covered in the next chapter):</p>
<ul>
<li>The argument <em>se = “hetero”</em> tells R to calculate heteroscedasticity-robust standard errors, which will be discussed later in chapter 4. Just know it is standard to do so.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>ate <span class="ot">&lt;-</span> <span class="fu">feols</span>(y <span class="sc">~</span> treatment, <span class="at">data =</span> mydata, <span class="at">se =</span> <span class="st">"hetero"</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ate)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For example:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>ate <span class="ot">&lt;-</span> <span class="fu">feols</span>(pct_missing <span class="sc">~</span> treat_invite, <span class="at">data =</span> dta, <span class="at">se =</span> <span class="st">"hetero"</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ate)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>OLS estimation, Dep. Var.: pct_missing
Observations: 477
Standard-errors: Heteroskedasticity-robust 
              Estimate Std. Error   t value  Pr(&gt;|t|)    
(Intercept)   0.252106   0.026366  9.561612 &lt; 2.2e-16 ***
treat_invite -0.023147   0.032845 -0.704753   0.48131    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
RMSE: 0.34285   Adj. R2: -0.001082</code></pre>
</div>
</div>
<p>We can see the output estimate of <em>treat_invite</em> is the same as the example above using the difference-in-means estimator.</p>
<p><br></p>
</section>
<section id="hypothesis-testing-in-experiments" class="level2">
<h2 class="anchored" data-anchor-id="hypothesis-testing-in-experiments">Hypothesis Testing in Experiments</h2>
<p>For hypothesis testing in R, we use the regression estimator (again, will be covered in chapter 3).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>ate <span class="ot">&lt;-</span> <span class="fu">feols</span>(y <span class="sc">~</span> treatment, <span class="at">data =</span> mydata, <span class="at">se =</span> <span class="st">"hetero"</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ate)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For example:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>ate <span class="ot">&lt;-</span> <span class="fu">feols</span>(pct_missing <span class="sc">~</span> treat_invite, <span class="at">data =</span> dta, <span class="at">se =</span> <span class="st">"hetero"</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ate)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>OLS estimation, Dep. Var.: pct_missing
Observations: 477
Standard-errors: Heteroskedasticity-robust 
              Estimate Std. Error   t value  Pr(&gt;|t|)    
(Intercept)   0.252106   0.026366  9.561612 &lt; 2.2e-16 ***
treat_invite -0.023147   0.032845 -0.704753   0.48131    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
RMSE: 0.34285   Adj. R2: -0.001082</code></pre>
</div>
</div>
<p>We can see that the output of <em>treat_invite</em> does not have stars, and its p-value is 0.48131, which is way above the rejection threshold of 0.05. Thus, it is not statistically significant.</p>
<ul>
<li>We can also see the t-value is calculated here if you need it.</li>
</ul>
<p><br></p>
</section>
<section id="confidence-intervals-in-experiments" class="level2">
<h2 class="anchored" data-anchor-id="confidence-intervals-in-experiments">Confidence Intervals in Experiments</h2>
<p>For confidence intervals in R, we first run a regression (see above), then use the <em>confint</em> command:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(ate)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For example:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(ate)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                   2.5 %     97.5 %
(Intercept)   0.20029633 0.30391487
treat_invite -0.08768618 0.04139144</code></pre>
</div>
</div>
<p>Here in the <em>treat_invite</em> row, we can see the lower and upper bounds of the 95% confidence interval for the difference-in-means estimator.</p>
<p><br></p>
</section>
<section id="balance-tables" class="level2">
<h2 class="anchored" data-anchor-id="balance-tables">Balance Tables</h2>
<p>(Once again, chapter 3 will make things clearer). To create a balance table, you first run multiple regressions where the output variable is the covariate, and the explanatory variable is the treatment variable. Then, we use the <em>screenreg()</em> funtion or <em>texreg()</em> function to create a balance table.</p>
<p>For example:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">feols</span>(head_edu <span class="sc">~</span> treat_invite, <span class="at">data =</span> dta, <span class="at">se =</span> <span class="st">"hetero"</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">feols</span>(mosques <span class="sc">~</span> treat_invite, <span class="at">data =</span> dta, <span class="at">se =</span> <span class="st">"hetero"</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>m3 <span class="ot">&lt;-</span> <span class="fu">feols</span>(pct_poor <span class="sc">~</span> treat_invite, <span class="at">data =</span> dta, <span class="at">se =</span> <span class="st">"hetero"</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>m4 <span class="ot">&lt;-</span> <span class="fu">feols</span>(total_budget <span class="sc">~</span> treat_invite, <span class="at">data =</span> dta, <span class="at">se =</span> <span class="st">"hetero"</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="fu">screenreg</span>(<span class="at">l =</span> <span class="fu">list</span>(m1, m2, m3, m4),</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">custom.model.names =</span> <span class="fu">c</span>(<span class="st">"Village Head Education"</span>, <span class="st">"Mosques per 1,000"</span>, <span class="st">"Prop. of Households in Poverty"</span>, <span class="st">"Total Budget"</span>),</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">custom.coef.names =</span> <span class="fu">c</span>(<span class="st">"Intercept"</span>, <span class="st">"Treatment"</span>),</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">digits =</span> <span class="dv">3</span>, <span class="at">include.rsquared =</span> <span class="cn">FALSE</span>, <span class="at">include.adjrs =</span> <span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
==================================================================================================
           Village Head Education  Mosques per 1,000  Prop. of Households in Poverty  Total Budget
--------------------------------------------------------------------------------------------------
Intercept   11.503 ***               1.474 ***          0.405 ***                      81.983 *** 
            (0.196)                 (0.060)            (0.015)                         (2.980)    
Treatment   -0.069                  -0.062              0.009                          -1.760     
            (0.241)                 (0.074)            (0.019)                         (4.179)    
--------------------------------------------------------------------------------------------------
Num. obs.  562                     565                560                             565         
==================================================================================================
*** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05</code></pre>
</div>
</div>
<p>We can see we have a balance table here. If you prefer a latex output (which can be put into a document), then change <em>screenreg()</em> to <em>texreg()</em>.</p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>