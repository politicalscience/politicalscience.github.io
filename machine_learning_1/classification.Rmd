---
title: "Classification Methods"
output: html_document
date: "2024-09-01"
---

```{=html}
<style type="text/css">
  body{
  font-size: 12pt;
  line-height: 150%;
}
</style>
```
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

[Course Homepage](https://politicalscience.github.io/#machine1)

## Table of Contents {#contents}

-   [Naive Bayes Classifier](#naive)

-   [Tree-Based Classifiers](#trees)

-   [Evaluating Classification Models](#evaluation)

<br />

------------------------------------------------------------------------

Remember to load tidyverse.

```{r, message = FALSE}
library(tidyverse)
```

Let us also load the dataset we will be using for these examples (feel free to load your own dataset)

```{r, message = FALSE}
df <- read_csv("voctaxdata.csv")
```

------------------------------------------------------------------------

[Table of Contents](#contents){data-heading="Table of Contents"} \| [Course Homepage](https://politicalscience.github.io/#machine1)

# Naive Bayes Classifier {#naive}

[Intuition and Theory](#1001) \| [Example in R](#1002)

### Intuition and Theory {#1001}

So far in this course, we have focused on predicting $y$ values. However, what about when we have a categorical or binary $y$, and our goal is to predict which category $k$ a specific observation falls into? This is called classification.

An example of a binary $y$ variable in which classification would be relevant is the following:

$$
y = \left\{    \begin{array}{lr}        
k = 0, & \text{Not a Democracy }\\        k=1, & \text{Democracy}    \end{array}\right\}
$$

Where we would try to predict what category of $y$ an observation falls into based on its $x$ values, by first predicting the probability of being in $y=k$, $\hat{\pi}$, and the assigning observations based on $\hat{\pi}$ to categories.

<br />

In [Statistics II: Regression Analysis](https://politicalscience.github.io/#stats2), we covered logistic regression, which is the more "traditional" method of classification prediction. Logistic regression a transformation of the linear regression model to ensure probabilities predicted remain between 0 and 1.

$$
\text{Logistic transformation function} \space f(m) = \frac{e^m}{1+e^m}
$$

$$
\text{where the linear model is the input:} \space m = \hat{\mathbf{\beta}}_0 + \hat{\mathbf{\beta}}_1 x_i
$$

$$
\text{and the resulting model is: } \hat{Ï€_i} = \frac{e^{\hat{\mathbf{\beta}}_0 + \hat{\mathbf{\beta}}_1 x}}{1 + e^{\hat{\mathbf{\beta}}_0 + \hat{\mathbf{\beta}}_1 x}}
$$

<br />

However, there is an alternative approach to estimate the probabilities of being in a category of $y$: the Naive Bayes Classifier.

Naive Bayes, as the name suggests, relies on Bayes' Rule, which states the following:

$$
P(A|B) = \frac{P(B|A) P(A)}{P(B)}
$$

-   Where $P(A|B)$ is the probability of event A occurring, given $B$ is true.

-   Where $P(B|A)$ is the probability of event B occurring, given B is true.

-   Where $P(A)$ and $P(B)$ are the probabilities of observing $A$ and $B$ without any conditions (prior probabilities).

<br />

When we are making classifications, we are trying to predict the probability $\hat{\pi}$ of being in a certain category $y=k$, given the condition that our input values of our independent variables $X_i$ equals $x$. Thus:

$$
\hat{\pi} = P(Y=k|X_i = x)
$$

<br />

The equation above has the form of $P(A|B)$. Thus, using Bayes' rule, we know:

$$
P(Y=k|X_i=x) \propto P(Y)P(X_i=x|Y=k)
$$

Where:

-   $Y = k$ is when the output variable $Y$ has the value of category $k$

-   $X_i$ is the vector of covariates containing our independent variables.

-   $P(Y)$ is the probability that a randomly chosen observation is in class $k$ (called the prior). We can estimate this from the proportions of the sample

-   $P(X_i=x|Y=k)$ is the probability of a randomly chosen observation in class $k$, has the independent variable vector $X_i$ equal the value of $x$, our input values (This is called the likelihood).

    -   Basically, if we look at category $k$, what are the chances we get the input values that we are inputting into the model?

Note: I use $\propto$ (proportional) instead of $=$ (equal), because I have omitted the denominator to simplify the explanation.

-   The denominator does not depend on the category, so we will worry about it later.

<br />

Because $X_i$ is a vector of covariates, we, in theory, would need to work out $P(X_i=x|Y=k)$ from a multivariate probability distribution.

But, we can use a simplification step: assuming that features are independent.

-   This assumption is often not true, but it does simplify the estimation process.

When we make this simplification, since independent probabilities are simply multiplied, we know the second part of the equation (the likelihood) is:

$$
\text{Let us first shorthand } P(X_i = x | Y = k) \text{ to } P(x|k)
$$

$$
P(x|k) = P(x_1|k) * P(x_2 |k) *P(x_3 | k) ...
$$

$$
P(x|k) = \prod\limits_{j=1}^J P (x_j|k)
$$

<br />

Now, we can plug this likelihood back into the Bayes' Rule equation, replacing $P(X_i = x|Y = k)$ to get:

$$
P(Y_i = k|X_i) \propto P(k) \prod\limits_{j=1}^J P(x_j|k)
$$

<br />

But this equation (when we include the denominator) gives us probabilities. But, we want to classify - actually assign observations to categories.

-   Thus, we need to not only calculate probabilities, but assign each observation to a category depending on which category it is most probable to belong to.

<br />

To do this, we assign an algorithm to the function. This algorithm will return the class $k$, of the observation, which has the maximum probability. We actually can just ignore the denominator, since it is always constant within the same sample.

We introduce the the **argmax** function to assign the category, where the $k$ value with the highest result for the function is assigned the category. The result will be the prediction of which category of $y$ the observation belongs to:

$$
\hat{y}=\argmax_{k \in \{ 1, ... k\}} P(k) \prod\limits_{j=1}^J P(x_j|k) 
$$

<br />

Despite the very strong (and often not met) assumptions that Naive Bayes makes, it still performs especially well.

-   Naive Bayes performs especially well when there are a lot of independent variables.

Thus, it is often the favoured technique for large models aiming to make classification predictions.

<br />

### Example in R {#1002}

To run Naive Bayes, we need the library **e1071**:

```{r, message = FALSE}
library(e1071)
```

We can run a Naive Bayes with the function **naiveBayes()**. Let us first generate the model, then generate the predictions. The syntax is as follows:

```{r, eval = FALSE}

nb_model <- naiveBayes(Y ~ X1 + X2, data = df)
```

These are the parts of the syntax that can be altered:

-   **nb_model** is the variable I am saving my model to. *You can name this anything you want to.*

-   **Y** is the Y variable (Dependent variable) you are trying to predict, and **X1, X2** are the X variables (independent variable) you are using to get your prediction. *Replace these with the variables you want to use.*

    -   NOTE: Always put the Y variable before the X variable. Separate the two with a tilda **\~**
    -   NOTE: You can add more simply by using a **+** sign and adding another variable.

-   **df** is the name of the data frame that I am drawing these X and Y variables from. *Replace this with the name of your data frame.*

<br />

Now, let us generate predictions for our sample. You can predict in-sample data by setting **newdata** = the data frame you used for regression. You can predict out-of-sample data by using a dataframe with the same variables but new values. The syntax is as follows:

```{r, eval = FALSE}
#create new df for comparison of actual and prediction
nb_results <- df %>%
  select(Y) #optional, may help with readability

# newdata is what values of X1, X2... to predict for.
nb_results$prediction <- predict(nb_model, newdata = df)

# brief glimpse of the results
head(nb_results)
```

These are the parts of the syntax that can be altered:

-   **nb_results** is the results data frame I am creating. *You can name this anything you want to.*

-   **Y** is the Y variable I am trying to predict. *Replace this with the name of your Y variable.*

-   **nb_model** is the variable I am saved my prior model to. *Rename this to what your prior model was named.*

-   **df** is the name of the data frame that houses the $x$ values I want to predict for. *Replace this with the name of your data frame with the* $x$ *values you want to predict with.*

<br />

Take the following examples, where I predict whether a country is a **Liberal Market Economy (0) or Coordinated Market Economy (1)**. (These are topics from Comparative Political Economy).

```{r}

#Naive Bayes model
nb_model <- naiveBayes(as.factor(voc) ~ taxpercent + gini + econglobal, data = df)

#Add predictions to new data frame
nb_results <- df %>%
  select(voc) #optional, may help with readability

# newdata is what values of X1, X2... to predict for.
nb_results$prediction <- predict(nb_model, newdata = df)

# brief glimpse of the results
head(nb_results)
```

We will talk about prediction accuracy metrics in the later section on [Evaluating Classification Models](#evaluation).

<br />

------------------------------------------------------------------------

[Table of Contents] \| [Course Homepage](https://politicalscience.github.io/#machine1)

# Tree-Based Classifiers {#trees}

[Intuition and Theory](#2001) \| [Example in R](#2002)

### Intuition and Theory {#2001}

In the previous lesson on [Tree-Based Prediction Methods](https://politicalscience.github.io/machine_learning_1/trees.html), we covered the prediction methods of Bagging and Random Forest.

In that lesson, we focused on how Bagging and Random Forest could be used to predict continuous $y$ variables. However, Bagging and Random Forest can also be applied to classification with a few small modifications.

<br />

Bagging and Random Forest work in almost the same way for classification (If you need a refresher on how they work, check out the lesson [Tree-Based Prediction Methods](https://politicalscience.github.io/machine_learning_1/trees.html)).

In Tree-Based Prediction Models, to determine at which threshold to split $x$, the computer will find the optimal $x$ threshold for splitting based on which value reduces the residual sum of squares (RSS) the most.

$$
RSS = \sum\limits_{i=1}^{n} (y_i - \hat{y}_i)
$$

<br />

However, with classification, this isn't possible! Why? Well, there isn't really a "residual" in classification as there is on a mis-prediction.

Instead of finding the optimal $x$ splitting threshold based on Residual Sum of Squares (RSS), we instead use the **Classification Error Rate**.

The classification error rate is the fraction of the observations, that were predicted in a certain category, but don't belong to that category.

So, in Tree-Based Classifiers, to determine at which threshold to split $x$, the computer will find the optimal $x$ threshold for splitting based on which value reduces the Clasification Error Rate the most

Aside from this, classification trees work the same way.

<br />

### Example in R {#2002}

To conduct Bagging and Random Forest, wee need the package **randomForest**:

```{r, message = FALSE}
library(randomForest)
```

<br />

Bagging in R is conducted using the **randomForest()** function. We can view the summary by simply printing the regression variable.

```{r, eval = FALSE}

# Remember to install and load package randomForest

# set a seed to keep the same results when we re-run
set.seed(100)

bagging <- randomForest(Y ~ .,
                        data = df,
                        na.action = na.omit,
                        mtry = 9, # set to number of IV
                        importance = TRUE)

# call model variable to see output
bagging
```

These are the parts of the syntax that can be altered:

-   **bagging** is the variable I am saving my regression model to. *You can name this anything you want to.*

-   **Y** is the Y variable (Dependent variable) you are trying to predict. *Replace this with the variables you want to use.*

-   "**.**" after the tilda **\~** tells R to include all other variables in the data frame as independent variables. This is very common for Bagging since you will typically include all variables.

    -   Note: Make sure to de-select variables you don't want to include in the model, such as ID, date, etc.

-   **df** is the name of the data frame that I am drawing these X and Y variables from. *Replace this with the name of your data frame.*

-   NOTE: Remember to include the sections **na.action = na.omit**, and **importance = TRUE**.

<br />

To create a Random Forest model, the syntax is the exact same, except for the fact we set **mtry** to the square root of the number of independent variables in your regression.

```{r, eval = FALSE}
# Remember to install and load package randomForest

# set a seed to keep the same results when we re-run
set.seed(100)

randomforest <- randomForest(Y ~ .,
                        data = df,
                        na.action = na.omit,
                        mtry = 3, # square root of number of IV
                        importance = TRUE)

# call model variable to see output
randomforest
```

<br />

We can generate predictions with the **predict()** function:

```{r, eval = FALSE}
#create new df for comparison of actual and prediction
df_results <- df %>%
  select(Y) #optional, may help with readability

# newdata is what values of X1, X2... to predict for.
df_results$prediction <- predict(bagging, newdata = df)

# brief glimpse of the results
head(df_results)
```

These are the parts of the syntax that can be altered:

-   **df_results** is the results data frame I am creating. *You can name this anything you want to.*

-   **Y** is the Y variable I am trying to predict. *Replace this with the name of your Y variable.*

-   **bagging** is the variable I am saved my prior model to. *Rename this to what your prior model was named.*

-   **df** is the name of the data frame that houses the $x$ values I want to predict for. *Replace this with the name of your data frame with the* $x$ *values you want to predict for.*

<br />

Take the following examples, where I predict whether a country is a **Liberal Market Economy (0) or Coordinated Market Economy (1)**. (These are topics from Comparative Political Economy).

```{r}
# Remember to install and load package randomForest

# set a seed to keep the same results when we re-run
set.seed(100)

bagging <- randomForest(as.factor(voc) ~ taxpercent + gini + econglobal,
                        data = df,
                        na.action = na.omit,
                        mtry = 3, # set to number of IV
                        importance = TRUE)

# call model variable to see output
bagging

```

We will discuss the output confusion matrix in the later section on [Evaluating Classification Models](#evaluation).

<br />

Let us generate in-sample predictions for this model:

```{r}
#create new df for comparison of actual and prediction
df_results <- df %>%
  select(voc) #optional, may help with readability

# newdata is what values of X1, X2... to predict for.
df_results$prediction <- predict(bagging, newdata = df)

# brief glimpse of the results
head(df_results)
```

<br />

------------------------------------------------------------------------

[Table of Contents] \| [Course Homepage](https://politicalscience.github.io/#machine1)

# Evaluating Classification Models {#evaluation}

[Intuition and Theory](#3001) \| [Example in R](#3002)

### Intuition and Theory {#3001}

Now that we have learned different classification methods, how do we choose the right one? How do we evaluate the performance of our classification methods, just as we did for prediction methods?

The simplest metric is just what proportion our method got correct/wrong:

-   Error rate: The percentage of observations that our classification method got wrong.

-   Accuracy: The percentage of observations that our classification method got right.

<br />

We can dig more into detail. If we have a binary $y$ variable, we do this by determining two metrics:

-   False positive rate: The observations that are $y=0$, but our classification method predicted $\hat{y} = 1$

-   False negative rate: The observations that are $y=1$, but our classification method predicted $\hat{y} = 0$

<br />

We can also do the inverse: instead of calculating error rates like above, we can calculate accuracy rates. There are two metrics for this:

-   Specificity: the observations that are $y=0$, and our classification method correctly predicted $\hat{y} = 0$

-   Sensitivity: the observations that are $y=1$, and our classification method correctly predicted $\hat{y} = 1$

<br />

Is specificity or sensitivity more important? Is false positive rate or false negative rate more important?

-   Well, it depends on the application of our model.

-   If our model tests for extremely dangerous diseases, its probably better if the model detects some false positives, rather than under-detects people who are actually sick.

-   But, for judicial systems, since we are afraid of putting an innocent person in jail, we might prefer less false positives, and more false negatives.

Choosing the right model requires some subjectivity here.

<br />

### Example in R {#3002}

If we have a Naive Bayes classifier, we can generate a table comparing our predictions to the actual. This table is often called a **confusion matrix**. To do this, make sure we have already generated the predictions, and stored them in the same data frame as the actual values.

Then, we generate the confusion matrix. The syntax is as follows:

```{r, eval = FALSE}

table(Prediction = df_results$prediction, Actual = df_results$Y)
```

These are the parts of the syntax that can be altered:

-   **df_results\$prediction** is the prediction column of our data frame with results. *Change the part before \$ to the data frame name that you stored your prediction to, and the part after \$ to the variable you stored your prediction to.*

-   **Y** is the Y variable in our data frame with the actual values of y. *Change this to the name of your Y variable.*

<br />

For Bagging/Random Forest, the default output includes a confusion matrix. We just simply print the model. The syntax is as follows:

```{r, eval = FALSE}

print(bagging)
```

These are the parts of the syntax that can be altered:

-   **bagging** is the variable I am saved my prior model to. *Rename this to what your prior model was named.*

<br />

For example, let us generate the confusion matrices of the Naive Bayes and Bagging Model we ran in the earlier sections. Let us also calculate some key metrics:

Naive Bayes:

```{r}

table(Prediction = nb_results$prediction, Actual = nb_results$voc)
```

Let us calculate some metrics:

-   Accuracy: $\frac{100+136}{100+17+2+136} = 92.54 \%$

-   Error Rate: $\frac{17+2}{100+17+2+136}=7.45 \%$

-   Specificity: $\frac{100}{100+2}=98.03 \%$

-   Sensitivity: $\frac{136}{17+136}=88.88 \%$

<br />

For Bagging:

```{r}
print(bagging)
```

Let us calculate some metrics:

-   Accuracy: $\frac{102+150}{102+0+3+150} = 98.82 \%$

-   Error Rate: Already given in output as $1.18 \%$

-   Specificity: $\frac{102}{102+3}=97.14 \%$

-   Sensitivity: $\frac{150}{0+150}=100 \%$

<br />

------------------------------------------------------------------------

[Table of Contents] \| [Course Homepage](https://politicalscience.github.io/#machine1)
