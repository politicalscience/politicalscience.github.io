<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>10&nbsp; Multivariate Methods – Statistics for Political Science</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<link href="./references.html" rel="next">
<link href="./identify.html" rel="prev">
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="mathjax-config.js"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./glm.html">Part II: Applied Statistics</a></li><li class="breadcrumb-item"><a href="./multivariate.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Multivariate Methods</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Statistics for Political Science</a> 
    </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Part I: Theoretical Statistics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./random.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Random Variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Statistical Inference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mle.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Maximum Likelihood</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ols.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Least Squares Theory</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./causal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Causal Inference</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Part II: Applied Statistics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./glm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Generalised Linear Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dependent.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Dependent Data Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./nonlinear.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Non-Linear Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./identify.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Quasi-Experimental Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./multivariate.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Multivariate Methods</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul class="collapse">
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview"><span class="header-section-number">10.1</span> Overview</a></li>
  <li><a href="#principle-components-analysis" id="toc-principle-components-analysis" class="nav-link" data-scroll-target="#principle-components-analysis"><span class="header-section-number">10.2</span> Principle Components Analysis</a></li>
  <li><a href="#cluster-analysis" id="toc-cluster-analysis" class="nav-link" data-scroll-target="#cluster-analysis"><span class="header-section-number">10.3</span> Cluster Analysis</a></li>
  <li><a href="#factor-analysis" id="toc-factor-analysis" class="nav-link" data-scroll-target="#factor-analysis"><span class="header-section-number">10.4</span> Factor Analysis</a></li>
  <li><a href="#item-response-theory" id="toc-item-response-theory" class="nav-link" data-scroll-target="#item-response-theory"><span class="header-section-number">10.5</span> Item Response Theory</a></li>
  <li><a href="#latent-class-models" id="toc-latent-class-models" class="nav-link" data-scroll-target="#latent-class-models"><span class="header-section-number">10.6</span> Latent Class Models</a></li>
  <li><a href="#structural-equation-modelling" id="toc-structural-equation-modelling" class="nav-link" data-scroll-target="#structural-equation-modelling"><span class="header-section-number">10.7</span> Structural Equation Modelling</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./glm.html">Part II: Applied Statistics</a></li><li class="breadcrumb-item"><a href="./multivariate.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Multivariate Methods</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Multivariate Methods</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>So far, we have focused on models with one outcome variable <span class="math inline">\(Y\)</span>. However, in many statistical situations, we have multiple outcome variables.</p>
<p>In this chapter, we start by discussing unsupservised learning methods including principle components analysis and cluster analysis. Then, we discuss a series of latent variable models, including factor anlaysis, item response theory, and latent class models.</p>
<p><br></p>
<section id="overview" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="overview"><span class="header-section-number">10.1</span> Overview</h2>
<p>In statistics, we often want to measure concepts. However, some concepts are not directly observable. For example, we cannot measure how happy someone is, or the quality of life in a country. However, these concepts cause certain indicator variables to change. For example, if quality of life in a country is higher, you might expect that country to exhibit higher salaries, better work-life balance, good health care and education, and so on.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/clipboard-1663993722.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:50.0%"></p>
</figure>
</div>
<p>These multiple observed indicator variables <span class="math inline">\(x_1, \dots, x_p\)</span> themselves are not that interesting for us - however, when combined together, they can be used to create interesting results, or as measures of some concept of interest to us. The main multivariate approaches include:</p>
<table class="table-bordered caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 74%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Uses</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Principle Components Analysis</td>
<td>For dimensional reduction and interpreting the main drivers of variation in observed variables.</td>
</tr>
<tr class="even">
<td>Cluster Anlaysis</td>
<td>For understanding hidden patterns and structures within our observed variables.</td>
</tr>
<tr class="odd">
<td>Factor Analysis</td>
<td>For measuring continuous latent variables with continuous observed variables.</td>
</tr>
<tr class="even">
<td>Item Response Theory</td>
<td>For measuring continuous latent variables with binary/categorical observed variables.</td>
</tr>
<tr class="odd">
<td>Latent Class Models</td>
<td>For measuring categorical latent variables with categorical observed variables.</td>
</tr>
<tr class="even">
<td>Structural Equation Models</td>
<td>To link latent variable models together through larger models of relationships.</td>
</tr>
</tbody>
</table>
<p><br></p>
</section>
<section id="principle-components-analysis" class="level2" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="principle-components-analysis"><span class="header-section-number">10.2</span> Principle Components Analysis</h2>
<p>Principle components analysis (PCA) is a way to combine multiple observed variables into fewer variables, which is a process called dimensional reduction. We start off with a set of observed variables <span class="math inline">\(\b x_t = (x_1, x_2, \dots, x_p)_t\)</span> for each observation <span class="math inline">\(t\)</span>. Each observed variable <span class="math inline">\(x_i\)</span> has a variance <span class="math inline">\(\V x_i\)</span>, and their total variance is <span class="math inline">\(\V x_1 + \dots + \V x_p\)</span>.</p>
<p>PCA takes these <span class="math inline">\(p\)</span> number of original variables <span class="math inline">\(x_1, \dots, x_p\)</span>, and calculates a set of <span class="math inline">\(p\)</span> new variables called principle components <span class="math inline">\(y_1, \dots, y_p\)</span>. Each principle component <span class="math inline">\(y_j\)</span> is made up a linear combination of the original variables:</p>
<p><span class="math display">\[
y_j = \ a_{1j}x_1 + a_{2j}x_2 + \dots + a_{pj}x_p
\]</span></p>
<p>All of the principle components together have the same variance as the original variables: <span class="math inline">\(\sum \V y_j = \sum \V x_i\)</span>. Thus, the new principle components carry the same information/variation as the original variables, just with a different distribution between each variable. Each principle component is uncorrelated with the next principle component - thus each PC conveys distinct aspects of the data.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset nav-pills">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" aria-current="page">Estimation in R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Mechanics</a></li></ul>
<div class="tab-content nav-pills">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<p>To estimate principle components, we use the <em>princomp()</em> function:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>pca <span class="ot">&lt;-</span> <span class="fu">princomp</span>(<span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3, <span class="at">data =</span> mydata,</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>                <span class="at">cor =</span> <span class="cn">TRUE</span>, <span class="at">scores =</span> <span class="cn">TRUE</span>, <span class="at">na.action =</span> na.exclude)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(pca)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This will generate all the principle components (<span class="math inline">\(p\)</span> number of them). Principle components are labelled in order of the variance they contain. So, principle component <span class="math inline">\(y_1\)</span> will have more variance than principle component <span class="math inline">\(y_2\)</span>, and so on. The proportion of total variance in all of the <span class="math inline">\(x_1, \dots, x_p\)</span> the first <span class="math inline">\(q\)</span> principle components will explain is</p>
<p><span class="math display">\[
\frac{\sum_{j=1}^q \V y_j}{\sum_{i=1}^p \V x_i} = \frac{\lambda_1 + \lambda_2 + \dots + \lambda_q}{\lambda_1 + \lambda_2 + \dots + \lambda_1 + \dots + \lambda_p}
\]</span></p>
<p>Frequently, the first few principle components will explain around 70-80% of the total variation in all of <span class="math inline">\(x_1, \dots, x_p\)</span>. Thus, we can reduce the number of variables from <span class="math inline">\(p\)</span> to just 2-3 principle components. A screeplot can visualise this:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">screeplot</span>(pca, <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">main =</span> <span class="st">""</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<p>We can rewrite each principle component <span class="math inline">\(y_j\)</span> in terms of linear algebra:</p>
<p><span class="math display">\[
y_j = \b a^\top_j \b x \quad \iff \quad y_j = \begin{pmatrix}
a_{ij} &amp; a_{2j} &amp; \dots &amp; a_{pj} \end{pmatrix}
\begin{pmatrix} x_1 \\ x_2 \\ \vdots \\ x_p
\end{pmatrix}
\]</span></p>
<p>And all the principle components <span class="math inline">\(\b y = (y_1, \dots, y_p)\)</span> can be expressed as</p>
<p><span class="math display">\[
\b y = \b A^\top \b x , \quad \b A = \begin{pmatrix}
\b a_1 &amp; \b a_2 &amp; \dots &amp; \b a_p \end{pmatrix}
\]</span></p>
<p>The weights <span class="math inline">\(a_{ij}\)</span> of the PCs are calculated from eigenvalue decomposition of the covariance matrix <span class="math inline">\(\b\Sigma\)</span> of observed variables <span class="math inline">\(x_1, \dots, x_p\)</span>. We assume that <span class="math inline">\(\b\Sigma\)</span> has <span class="math inline">\(p\)</span> distinct positive eigenvalues, denoted <span class="math inline">\(\lambda_1 &gt; \lambda_2 &gt; \dots &gt; \lambda_p &gt; 0\)</span>. By applying eigenvalue decomposition to matrix <span class="math inline">\(\b\Sigma\)</span>, we get a matrix <span class="math inline">\(\b A\)</span> made up of eigenvectors of <span class="math inline">\(\b\Sigma\)</span>, and a diagonal matrix <span class="math inline">\(\b D\)</span> with eigenvalues <span class="math inline">\(\lambda\)</span> on its diagonal:</p>
<p><span class="math display">\[
\b\Sigma = \b{ADA}^{-1}, \quad \b D = \begin{pmatrix}
\lambda_1 &amp; &amp; \\
&amp; \lambda_2  &amp; \\
&amp; &amp; \ddots
\end{pmatrix}, \quad \b A = \begin{pmatrix}
\b a_1 &amp; \b a_2 &amp; \dots &amp; \b a_p \end{pmatrix}
\]</span></p>
<p>Each eigenvalue <span class="math inline">\(\lambda_j\)</span> corresponds to an eigenvector <span class="math inline">\(\b a_j\)</span>, which is the weights vector of the <span class="math inline">\(j\)</span>th principle component. The variance of each PC <span class="math inline">\(y_j\)</span> is equivalent to <span class="math inline">\(\lambda_j\)</span>, the <span class="math inline">\(j\)</span>th eigenvalue.</p>
</div>
</div>
</div>
<p>We can interpret our PCA in 3 ways:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset nav-pills">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">Weights</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">Component Loadings</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-3" role="tab" aria-controls="tabset-2-3" aria-selected="false">PC Scores</a></li></ul>
<div class="tab-content nav-pills">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<p>Remember the form of each principle component <span class="math inline">\(y_j\)</span> is:</p>
<p><span class="math display">\[
y_j = \ a_{1j}x_1 + a_{2j}x_2 + \dots + a_{pj}x_p
\]</span></p>
<p><span class="math inline">\(a_{ij}\)</span> are the weights of each observed variable <span class="math inline">\(x_1, \dots, x_p\)</span> in a principle component <span class="math inline">\(y_j\)</span>. We can calculate weights in R as follows:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>pca_weights <span class="ot">&lt;-</span> <span class="fu">loadings</span>(pca)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(pca_weights, <span class="at">cutoff =</span> <span class="dv">0</span>, <span class="at">digits =</span> <span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The larger (both negative or positive) a weight for a variable means that variable contributes more to the specific principle component <span class="math inline">\(y_j\)</span>. For example, take this table:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/clipboard-1765056456.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:65.0%"></p>
</figure>
</div>
<p>We can see for component <span class="math inline">\(y_2\)</span>, the observed variable <em>UN</em> has a close to 0 weight. That implies component <span class="math inline">\(y_2\)</span> is not really measuring <em>UN</em>. We can also see the <span class="math inline">\(y_2\)</span> has high negative weight for police, which indicates as police increases, <span class="math inline">\(y_2\)</span> decreases. Using these weights, we can create an interpretation for each principle component.</p>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<p>The component loadings <span class="math inline">\(a_{ij}^*\)</span> are a standardised/normalised form of weights:</p>
<p><span class="math display">\[
a_{ij}^* = \sqrt{\lambda_j} \cdot a_{ij} \ = \ sd(y_j) \cdot a_{ij}
\]</span></p>
<p>When PCA is done on the correlation matrix (which the code implementation for R does), the component loadings <span class="math inline">\(a_{ij}^*\)</span> also eqwual the correlation between a given observed variable <span class="math inline">\(x_i\)</span> and the principle component <span class="math inline">\(y_j\)</span>.</p>
<p><span class="math display">\[
a_{ij}^* = Corr(x_i, y_j)
\]</span></p>
<p>We can calculate component loadings in R by:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>pca_weights <span class="ot">&lt;-</span> <span class="fu">loadings</span>(pca)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>sqrt_lambda <span class="ot">&lt;-</span> pca<span class="sc">$</span>sdev</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">t</span>(<span class="fu">t</span>(pca_weights)<span class="sc">*</span>sqrt_lambda), <span class="at">cutoff =</span> <span class="dv">0</span>, <span class="at">digits =</span> <span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/clipboard-396869437.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:65.0%"></p>
</figure>
</div>
<p>The interpretation of this table is almost identical to the interpretation of weights.</p>
</div>
<div id="tabset-2-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-3-tab">
<p>For each unit <span class="math inline">\(t\)</span> in our data, we can calculate a component score for each principle component <span class="math inline">\(y_j\)</span>. This is basically the <span class="math inline">\(y_j\)</span> value for unit <span class="math inline">\(t\)</span>:</p>
<p><span class="math display">\[
y_j = a_{1j}z_1 + a_{2j}z_2 + \dots + a_{pj}z_p
\]</span></p>
<p>Component scores are already calculated in the PCA estimation. We can access them:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>pca<span class="sc">$</span>score</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>By doing this for each unit <span class="math inline">\(t\)</span> in our data, we now have a new variable <span class="math inline">\(y_j\)</span> that we can use for further analysis. This essentially allows us to condense our <span class="math inline">\(p\)</span> number of observed variables <span class="math inline">\(x_1, \dots, x_p\)</span> to a few (1-3) principle components <span class="math inline">\(y_j\)</span> which contain 70-80% of the variation in our original <span class="math inline">\(x_1, \dots, x_p\)</span>. This is extremely useful for two reasons:</p>
<ol type="1">
<li>Reducing computational power. If we have a lot of observed variables (let us say 50-100 of them), many models without analytical solutions (so everything except OLS) will require a lot of computer power and resources to estimate. By reducing the number of variables and only using a few principle components, we get similar results with far less computing power.</li>
<li>Multicollinearity issues: closely correlated explanatory variables in regression models often reduces precision of our coefficient estimates. We can combine correlated variables into one or two principle components, which carry most of the same meaning, and since principle components are by design orthogonal (uncorrelated with each other), we completely solve the issue of multicollinearity.</li>
</ol>
</div>
</div>
</div>
<p><br></p>
</section>
<section id="cluster-analysis" class="level2" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="cluster-analysis"><span class="header-section-number">10.3</span> Cluster Analysis</h2>
<p><br></p>
</section>
<section id="factor-analysis" class="level2" data-number="10.4">
<h2 data-number="10.4" class="anchored" data-anchor-id="factor-analysis"><span class="header-section-number">10.4</span> Factor Analysis</h2>
<p>Latent variables <span class="math inline">\(\xi\)</span> (also called <strong>factors</strong>) are variables that we cannot directly measure. However, these latent variables <span class="math inline">\(\xi\)</span> can be measured through observed outcome variables <span class="math inline">\(Y_1, \dots, Y_p\)</span>, called <strong>items</strong>. Factor analysis assume that we have a set of continuous observed items <span class="math inline">\(Y_1, Y_2, \dots, Y_p\)</span>, that are all the result of some continuous latent factor variable <span class="math inline">\(\xi\)</span>.</p>
<p>The latent factor <span class="math inline">\(\xi\)</span> is assumed to be distributed <span class="math inline">\(\xi \sim \mathcal N(\kappa = 0, \ \phi = 1)\)</span>. We assume that each item <span class="math inline">\(X_i\)</span> is normally distributed, and is related to the latent factor <span class="math inline">\(\xi\)</span> by a linear model:</p>
<p><span class="math display">\[
Y_i = \tau_i + \lambda_i\xi + \delta_i, \quad \delta_i \sim \mathcal N(0, \theta_{ii})
\]</span></p>
<p><span class="math inline">\(\lambda_i\)</span> is the slope (called the <strong>factor loadings</strong>), which determines the relationship/covariance between factor <span class="math inline">\(\xi\)</span> and a specific item <span class="math inline">\(Y_i\)</span>. <span class="math inline">\(\delta_i\)</span> is the error term, and is called the <strong>unique factor</strong> - the part of the item not explained by the factor.</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
More Details on Assumptions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We make a few assumptions on this linear model above.</p>
<ol type="1">
<li>Error terms <span class="math inline">\(\delta_i\)</span> for each regression model between <span class="math inline">\(\xi\)</span> and <span class="math inline">\(Y_1, \dots, Y_p\)</span> is normally distributed with a mean of 0. <span class="math inline">\(\delta_i \sim \mathcal N(0, \theta_{ii})\)</span>.</li>
<li>Error terms <span class="math inline">\(\delta_1, \dots, \delta_p\)</span> of each model <span class="math inline">\(i\)</span> are uncorrelated with each other. This implies that correlations between <span class="math inline">\(Y_1, \dots, Y_p\)</span> are entirely explained by the latent factor <span class="math inline">\(\xi\)</span>.</li>
<li>Factor <span class="math inline">\(\xi\)</span> is uncorrelated with the error term <span class="math inline">\(\delta_i\)</span> (exogeneity).</li>
</ol>
</div>
</div>
</div>
<p>The estimation of this model involves maximum likelihood estimation:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset nav-pills">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true">Estimation in R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false">Mechanics</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-3" role="tab" aria-controls="tabset-3-3" aria-selected="false">Multiple Factors</a></li></ul>
<div class="tab-content nav-pills">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<p>Before we start, we must ensure our data has no missing values:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>no_na <span class="ot">&lt;-</span> <span class="fu">apply</span>(my_data, <span class="dv">1</span>, <span class="at">FUN=</span><span class="cf">function</span>(x){<span class="fu">all</span>(<span class="sc">!</span><span class="fu">is.na</span>(x))})</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>my_data <span class="ot">&lt;-</span> my_data[no_na,]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can estimate a factor analysis model with maximum likelihood estimation with the <em>psych</em> package and <em>GPA rotation</em>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>fa <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">fa</span>(my_data, <span class="at">nfactros =</span> <span class="dv">1</span>, <span class="at">fm =</span> <span class="st">"ml"</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(fa)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can also do factor anlaysis with multiple factors (see the third tab for more details):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># for orthogonal rotation (for data reduction)</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>fa <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">fa</span>(my_data, <span class="at">nfactros =</span> <span class="dv">2</span>, <span class="at">fm =</span> <span class="st">"ml"</span>, <span class="at">rotate =</span> <span class="st">"none"</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(fa)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># for oblique rotation (for interpretation)</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>fa <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">fa</span>(my_data, <span class="at">nfactros =</span> <span class="dv">2</span>, <span class="at">fm =</span> <span class="st">"ml"</span>, <span class="at">rotate =</span> <span class="st">"oblimin"</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(fa)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The output will provide a table of the loadings <span class="math inline">\(\lambda_i\)</span> for each item <span class="math inline">\(Y_i\)</span>. If you have multiple factors, ML1 represents <span class="math inline">\(\xi_1\)</span>, and ML2 represents <span class="math inline">\(\xi_2\)</span>, and so on. For oblique rotations, there is also a table of correlations between all the factors <span class="math inline">\(\xi_j\)</span>.</p>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<p>Given the linear models between <span class="math inline">\(Y_i\)</span> and <span class="math inline">\(\xi\)</span>, we know <span class="math inline">\(\E(Y_i | \xi) = \tau_i + \lambda_i \xi\)</span>. Since <span class="math inline">\(Y_i\)</span> is assumed to be normally distributed, we can determine the distribution of <span class="math inline">\(Y_i\)</span> as</p>
<p><span class="math display">\[
Y_i \sim \mathcal N(\tau_i + \lambda_i \xi, \ \ \lambda_i^2 \phi + \theta_{ii})
\]</span></p>
<p>Our theoretical variance-covariance matrix <span class="math inline">\(\b\Sigma\)</span> between <span class="math inline">\(X_1, \dots, X_p\)</span>, where the diagonals are the variances of <span class="math inline">\(X_1, \dots, X_p\)</span>, and the non-diagonals are <span class="math inline">\(Cov(X_n, X_m)\)</span> will be</p>
<p><span class="math display">\[
\b\Sigma =\begin{pmatrix}
\lambda_1^2 \phi + \theta_{11} &amp;  \lambda_1\phi\lambda_2 &amp; \dots &amp;  \lambda_1 \phi \lambda_p \\
\lambda_2 \phi \lambda_1 &amp; \lambda_2^2 \phi + \theta_{22} &amp; \dots &amp; \lambda_1 \phi \lambda_p \\
\vdots &amp; \dots &amp; \ddots &amp; \vdots \\
\lambda_p\phi\lambda_1 &amp; \lambda_p \phi \lambda_2 &amp; \dots &amp; \lambda_p^2 \phi + \theta_{pp}
\end{pmatrix}
\]</span></p>
<p>Since <span class="math inline">\(\phi = 1\)</span> by assumption, we can rewrite <span class="math inline">\(\b\Sigma\)</span> as:</p>
<p><span class="math display">\[
\b\Sigma = \b{\Lambda\Lambda^\top} + \b\Theta, \quad \b\Lambda = (\lambda_1, \dots, \lambda_p)^\top, \ \b\Theta = \theta_{ii} \b I
\]</span></p>
<p>Where <span class="math inline">\(\b\Lambda\)</span> is a vector of factor loadings <span class="math inline">\(\lambda_i\)</span>, and <span class="math inline">\(\b\Theta\)</span> is a diagonal matrix with diagonals being <span class="math inline">\(\theta_{ii}\)</span>. Our goal is to find the values of <span class="math inline">\(\b\Lambda\)</span> and <span class="math inline">\(\b\Theta\)</span> that maximise the likelihood of observing the data given the model. Thus, we can use maximum likelihood estimation. Based on the multivariate normal distribution, we can establish that the log-likelihood function is:</p>
<p><span class="math display">\[
\begin{align}
\ell(\b\Lambda, \b\Theta; \b S) &amp; = -\frac{n}{2}(\log |\b\Sigma| + \mathrm{Tr}(\b{S \Sigma}^{-1}) \\
&amp; =  -\frac{n}{2}(\log |\b{\Lambda\Lambda^\top} + \b\Theta | + \mathrm{Tr}(\b{S}(\b{\Lambda\Lambda^\top} + \b\Theta )^{-1})
\end{align}
\]</span></p>
<p>Where <span class="math inline">\(\b S\)</span> is the sample covariance matrix, <span class="math inline">\(\b\Sigma\)</span> is still our theoretical-implied covariance matrix from above, and <span class="math inline">\(\mathrm{Tr}(\cdot)\)</span> is the trace of a matrix. We can use an iterative algorithm such as Newton-Raphson to estimate <span class="math inline">\(\b\Lambda\)</span> and <span class="math inline">\(\b\Theta\)</span>.</p>
</div>
<div id="tabset-3-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-3-tab">
<p>We can have more than one latent factor <span class="math inline">\(\b\xi = (\xi_1, \dots, \xi_q)\)</span>. We assume all are standardly normally distributed as before. Each item <span class="math inline">\(X_1, \dots, X_p\)</span> is now related to each factor <span class="math inline">\(\xi_1, \dots, \xi_q\)</span> with a regression:</p>
<p><span class="math display">\[
X_i = \tau_i + \lambda_{i1}\xi_1 + \lambda_{i2}\xi_2 + \dots + \lambda_{i1} \xi_q + \delta_i, \quad \delta_i\sim\mathcal N(0, \theta_{ii})
\]</span></p>
<p>Each factor can be correlated with each other - which means <span class="math inline">\(Cov(\xi_j, \xi_k) = \phi_{jk}\)</span> must be estimated as well. The number of factors <span class="math inline">\(q\)</span> must be small enough given the number of items <span class="math inline">\(p\)</span> in order for our model to be identified:</p>
<p><span class="math display">\[
df = \frac{(p-q)^2-(p+1)}{2}≥ 0
\]</span></p>
<p>Finally, we have an issue of factor rotation - this is because our different factors can be rotated in infinitely many ways, and still produce the same model fit. The default rotation in many calculations <strong>orthogonal (perpendicular)</strong>, which means factors are uncorrelated. The result from this estimation is very similar to PCA, and is good for dimensional reduction.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/clipboard-198343310.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<p>However, for interpretation ease, it is often useful to use <strong>oblique</strong> rotations, where factors can be correlated. This is because oblique rotations will have more factor loadings of 0, which will allow us to be more clear with what a factor is measuring.</p>
</div>
</div>
</div>
<p>We can interpret our factor analysis models in a few ways:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset nav-pills">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true">Factor Loadings</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false">Factor Scores</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-3" role="tab" aria-controls="tabset-4-3" aria-selected="false">Model Fit</a></li></ul>
<div class="tab-content nav-pills">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<p>Our <span class="math inline">\(\hat\lambda_i\)</span> will be the estimated covariances/relationships between any item <span class="math inline">\(X_i\)</span> and the latent factor <span class="math inline">\(\xi\)</span>. If item <span class="math inline">\(x_i\)</span> has been standardised to a standard normal distribution, <span class="math inline">\(\hat\lambda_i\)</span> will also be the correlation between <span class="math inline">\(x_i\)</span> and <span class="math inline">\(\xi\)</span>.</p>
<ul>
<li>Also note that in terms of interpretation for multiple factors, <span class="math inline">\(\hat\lambda_{ij}\)</span> is only the covariance between <span class="math inline">\(X_i\)</span> and <span class="math inline">\(\xi_j\)</span> if all factors are uncorrelated. If factors are correlated, we lose this nice interpretation.</li>
</ul>
<p>We can interpret <span class="math inline">\(\xi\)</span> based on the items <span class="math inline">\(X_i\)</span> that have the largest factor loadings <span class="math inline">\(\hat\lambda_i\)</span>. Generally, if the factor <span class="math inline">\(\xi\)</span> has very close to 0 loadings for a certain item <span class="math inline">\(Y_i\)</span>, that factor is not measuring that item.</p>
<p>Recall that when we assumed <span class="math inline">\(\xi\)</span> is standardly normally distributed, the variances of <span class="math inline">\(X_i\)</span> (from the matrix above) become:</p>
<p><span class="math display">\[
\V X_i = \lambda_i^2 + \theta_{ii}
\]</span></p>
<ul>
<li><span class="math inline">\(\lambda_i^2\)</span> is the part of the variance in <span class="math inline">\(X_i\)</span> explained by the factor <span class="math inline">\(\xi\)</span>. This is known as the <strong>communality</strong> of <span class="math inline">\(X_i\)</span>.</li>
<li><span class="math inline">\(\theta_{ii}\)</span> is the part of <span class="math inline">\(X_i\)</span> not explained by the factor <span class="math inline">\(\xi\)</span>, and is called the <strong>unique variance</strong>.</li>
<li>The proportion <span class="math inline">\(\rho_i =\lambda_i^2 / (\lambda_i^2 + \theta_{ii})\)</span> is the proportion of variance in <span class="math inline">\(X_i\)</span> explained by our factor <span class="math inline">\(\xi\)</span>, called the <strong>reliability</strong>. This is the <span class="math inline">\(R^2\)</span> of factor analysis. If our items <span class="math inline">\(Y_i\)</span> are standardised, then <span class="math inline">\(\V Y_i = 1\)</span>, and the reliability can simply be calculated as <span class="math inline">\(1-\theta_{ii}\)</span>.</li>
</ul>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<p>Once we have estimated our model, we can predict the latent factor <span class="math inline">\(\xi\)</span> value for any individual <span class="math inline">\(t\)</span> in our data. The factor scores in factor analysis are given by:</p>
<p><span class="math display">\[
\tilde\xi_t = w_0 + w_1 X_{t1} + w_2 X_{t2} + \dots + w_p X_{tp}
\]</span></p>
<p>Factor scores are estimated with the model, and can be accessed with</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>fa<span class="sc">$</span>scores</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>These are linear combinations of <span class="math inline">\(X_1, \dots, X_p\)</span>, with weights <span class="math inline">\(w_i\)</span> determined by the strength of the relationship between <span class="math inline">\(X_i\)</span> and <span class="math inline">\(\xi\)</span> as estimated by <span class="math inline">\(\hat\lambda_i\)</span> and the unique variance <span class="math inline">\(\theta_{ii}\)</span>.</p>
<ul>
<li>If two items have the same communality <span class="math inline">\(\lambda_i^2\)</span>, the two items are measuring the same factor on same scales. If they are different, then different scales.</li>
<li>If two items have the same unique variance <span class="math inline">\(\theta_{ii}\)</span>, the two items are measuring the same factor with the same amount of error. If they are different, then different amount of error.</li>
</ul>
<p><u>Congeneric Measures</u> are when <span class="math inline">\(\lambda_i^2\)</span> and <span class="math inline">\(\theta_{ii}\)</span> are different for two items. <u>Tau-Equivalent measures</u> are when <span class="math inline">\(\lambda_i^2\)</span> is equivalent between two items, but <span class="math inline">\(\theta_{ii}\)</span> is different. <u>Parallel measures</u> are when <span class="math inline">\(\lambda_i^2\)</span> and <span class="math inline">\(\theta_{ii}\)</span> are equivalent between two items. If two items are parallel measures, they will get equal weights <span class="math inline">\(w\)</span> in the calculation of factor scores.</p>
</div>
<div id="tabset-4-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-3-tab">
<p>We can compare the fit between models in a few ways. First, for selecting whether or not to include items, we should look at the reliability of each item. If the reliability is very low, we may not want to include this item.</p>
<p>For nested models, since factor analysis is estimated with MLE, we can also do likelihood ratio tests, with the null hypothesis <span class="math inline">\(M_0\)</span> having less parameters, and alternative model <span class="math inline">\(M_1\)</span> having more parameters. If <span class="math inline">\(M_1\)</span> is statistically significant, it is the better model.</p>
<p>For non-nested models, we have a few options:</p>
<ol type="1">
<li>Information Criterion Statistics that come with MLE, such as AIC or BIC. Lower values indicate better model fit.</li>
<li>Global goodness of fit test - a likelihood ratio test, but our null model is our fitted model, and the alternate model is a hypothetically perfect model that estimates the sample covariance matrix perfectly. We do not want to reject the null (and want a higher p-value when comparing models), since we want our fitted model to be good. The downside of this is that these tests are sensitive to sample size - larger sample size means more likely to reject our fitted model.</li>
<li>Global fit indicies address the sample-size concern in global goodness of fit tests. These include root mean square error of approximation (RMSEA), standard root mean squared residual (SRMR), tucker and lewis index (TLI), and comparative fit index (CFI). These are not too important to understand, but are frequently reported alongside factor analysis models.</li>
</ol>
<p>We can also conduct statistical significance tests of individual <span class="math inline">\(\lambda_i\)</span> with a wald-test. Generally, our null is <span class="math inline">\(\lambda_i = 0\)</span>, so if this turns out to be insignificant, we can set <span class="math inline">\(\lambda_i=0\)</span> (for a confirmatory model with multiple factors for better interpretation), or eliminiate that item as it is not explaining a factor.</p>
</div>
</div>
</div>
<p><br></p>
</section>
<section id="item-response-theory" class="level2" data-number="10.5">
<h2 data-number="10.5" class="anchored" data-anchor-id="item-response-theory"><span class="header-section-number">10.5</span> Item Response Theory</h2>
<p>Latent variables <span class="math inline">\(\xi\)</span> (also called <strong>factors</strong>) are variables that we cannot directly measure. However, these latent variables <span class="math inline">\(\xi\)</span> can be measured through observed outcome variables <span class="math inline">\(Y_1, \dots, Y_p\)</span>, called <strong>items</strong>. Item Response Theory (IRT), also called Latent Trait Models, assume that we have at least 3 binary observed items <span class="math inline">\(Y_1, \dots, Y_p\)</span>. We have one continuous latent factor <span class="math inline">\(\xi\)</span>.</p>
<p>We assume the factor <span class="math inline">\(\xi\)</span> be normally distributed <span class="math inline">\(\xi \sim \mathcal N(\kappa = 0, \phi = 1)\)</span>.We assume that the relationship between an observed item <span class="math inline">\(Y_i\)</span> and the latent factor <span class="math inline">\(\xi\)</span> to be of the form of a binary logistic regression:</p>
<p><span class="math display">\[
\log\left(\frac{\pr_i(\xi)}{1 - \pr_i(\xi)}\right) = \tau_j + \lambda_j \xi,\quad \pr_i(\xi) = \P(Y_i = 1|\xi)
\]</span></p>
<p>The intercept parameter <span class="math inline">\(\tau_j\)</span> is known as the <strong>difficult parameter</strong>. It is the probability of a item <span class="math inline">\(Y_i\)</span> equalling 1, when the factor <span class="math inline">\(\xi = 0\)</span>. The coefficient <span class="math inline">\(\lambda_i\)</span> is the <strong>factor loading</strong>, which is also known as the discrimination parameter. This explains the relationship between the item <span class="math inline">\(Y_i\)</span> and <span class="math inline">\(\xi\)</span>.</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
More Details
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We can take the above equation, exponenting both sides and solving for <span class="math inline">\(\pr_i(\xi)\)</span>, getting:</p>
<p><span class="math display">\[
P(Y_i = 1|\xi) = \pr_i(\xi) = \frac{e^{\tau_i + \lambda_i\xi}}{1+e^{\tau_i + \lambda_i\xi}}
\]</span></p>
<p>This allows us to get fitted probabilities of how <span class="math inline">\(\xi\)</span> affects the probability of an item being <span class="math inline">\(Y_i = 1\)</span>. These fitted probabilities are called item response curves.</p>
<p>IRT can also be applied to items with three or more categories, although this is quite rare. We will use an ordinal logistic regression model (with cumulative probabilities), or a multinomial logistic regression model instead.</p>
</div>
</div>
</div>
<p>The estimation of this model involves maximum likelihood estimation:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset nav-pills">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-5-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-1" role="tab" aria-controls="tabset-5-1" aria-selected="true">Estimation in R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-2" role="tab" aria-controls="tabset-5-2" aria-selected="false">Mechanics</a></li></ul>
<div class="tab-content nav-pills">
<div id="tabset-5-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-5-1-tab">

</div>
<div id="tabset-5-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-2-tab">

</div>
</div>
</div>
<p>We can interpret our item response theory model in a few ways:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset nav-pills">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-6-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-1" role="tab" aria-controls="tabset-6-1" aria-selected="true">Factor Loadings</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-2" role="tab" aria-controls="tabset-6-2" aria-selected="false">Factor Scores</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-3" role="tab" aria-controls="tabset-6-3" aria-selected="false">Model Fit</a></li></ul>
<div class="tab-content nav-pills">
<div id="tabset-6-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-6-1-tab">
<p>The discrimination parameter <span class="math inline">\(\lambda_i\)</span> can be thought of the part of <span class="math inline">\(Y_i\)</span> that is explained by <span class="math inline">\(\xi\)</span>, and the difficulty parameter <span class="math inline">\(\tau_i\)</span> can be thought of the unique part of the item. However, neither are directly interpretable as variances unlike factor anlaysis.</p>
</div>
<div id="tabset-6-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-2-tab">
<p>Once we have estimated our model, we can predict the latent factor <span class="math inline">\(\xi\)</span> value for any individual <span class="math inline">\(t\)</span> in our data. The factor scores in IRT are caculated as the estimated mean of the factor <span class="math inline">\(\xi\)</span>, given the values of items <span class="math inline">\(Y_1, \dots, Y_p\)</span> for observation <span class="math inline">\(t\)</span>:</p>
<p><span class="math display">\[
\tilde\xi = \E(\xi | Y_1, \dots, Y_p)
\]</span></p>
<p>The scores will be a linear combination of items <span class="math inline">\(Y_1, \dots, Y_p\)</span>:</p>
<p><span class="math display">\[
\tilde\xi_t = \hat\lambda_1 Y_{t1} + \hat\lambda_2Y_{t2} + \dots + \hat\lambda_p Y_{tp}
\]</span></p>
<p>Factor scores are estimated with the model, and can be accessed with</p>
</div>
<div id="tabset-6-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-3-tab">

</div>
</div>
</div>
<p><br></p>
</section>
<section id="latent-class-models" class="level2" data-number="10.6">
<h2 data-number="10.6" class="anchored" data-anchor-id="latent-class-models"><span class="header-section-number">10.6</span> Latent Class Models</h2>
<p>Latent variables <span class="math inline">\(\xi\)</span> (also called <strong>factors</strong>) are variables that we cannot directly measure. However, these latent variables <span class="math inline">\(\xi\)</span> can be measured through observed outcome variables <span class="math inline">\(Y_1, \dots, Y_p\)</span>, called <strong>items</strong>. Latent Class Models assume that we have at least 3 categorical observed items <span class="math inline">\(Y_1, \dots, Y_p\)</span>. We have one categorical latent factor <span class="math inline">\(\xi\)</span>.</p>
<p>We assume the items <span class="math inline">\(Y_1, \dots, Y_p\)</span> are observed categorical items, with each item <span class="math inline">\(Y_j\)</span> having <span class="math inline">\(K_j\)</span> number of categories. Let factor <span class="math inline">\(\xi\)</span> be categorical with <span class="math inline">\(C\)</span> categories/classes, where <span class="math inline">\(C\)</span> is chosen by the user.</p>
<p>Our parameter of interest is the <strong>item response probability</strong>, which is the probability of an item <span class="math inline">\(Y_i\)</span> equals category <span class="math inline">\(k\)</span>, given <span class="math inline">\(\xi\)</span> equals category <span class="math inline">\(c\)</span>:</p>
<p><span class="math display">\[
\pr_{ikc} = \P(Y_i = k|\xi = c)
\]</span></p>
<p>The model that describes the relationship between item <span class="math inline">\(Y_i\)</span> and factor <span class="math inline">\(\xi\)</span> is given by:</p>
<p><span class="math display">\[
\log\left(\frac{\pr_{ikc}}{\pr_{i1c}}\right) = \tau_{ik} + \sum\limits_{d=2}^C \lambda_{ikd}D_d
\]</span></p>
<p>Where <span class="math inline">\(\lambda_{ik1} = 0\)</span>, and <span class="math inline">\(D_d\)</span> are dummy variables for latent classes/categories <span class="math inline">\(d = 2, \dots, C\)</span> of <span class="math inline">\(\xi\)</span>. Unlike the other two models, we cannot assume <span class="math inline">\(\xi\)</span> is normally distributed, since it is categorical. Instead, we assume <span class="math inline">\(\xi\)</span> is categorical with probabilities <span class="math inline">\(\alpha_c = \P(\xi = c)\)</span>.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset nav-pills">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-7-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-1" role="tab" aria-controls="tabset-7-1" aria-selected="true">Estimation in R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-7-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-2" role="tab" aria-controls="tabset-7-2" aria-selected="false">Mechanics</a></li></ul>
<div class="tab-content nav-pills">
<div id="tabset-7-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-7-1-tab">

</div>
<div id="tabset-7-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-7-2-tab">

</div>
</div>
</div>
<p>We can interpret our latent class models in a few ways:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset nav-pills">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-8-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-1" role="tab" aria-controls="tabset-8-1" aria-selected="true">Factor Loadings</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-8-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-2" role="tab" aria-controls="tabset-8-2" aria-selected="false">Factor Scores</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-8-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-3" role="tab" aria-controls="tabset-8-3" aria-selected="false">Model Fit</a></li></ul>
<div class="tab-content nav-pills">
<div id="tabset-8-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-8-1-tab">

</div>
<div id="tabset-8-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-8-2-tab">
<p>Once we have estimated our model, we can predict the latent factor <span class="math inline">\(\xi\)</span> value for any individual <span class="math inline">\(t\)</span> in our data. Instead of predicting a value of <span class="math inline">\(\xi\)</span> (since it is categorical in latent class models), we will classify observations <span class="math inline">\(t\)</span> into one of the categories/classes of <span class="math inline">\(\xi\)</span>. We estimate the probability of an observation being in every class <span class="math inline">\(c\)</span>, given their values of <span class="math inline">\(Y_1, \dots, Y_p\)</span>:</p>
<p><span class="math display">\[
\hat\P(\xi = c|Y_1 = k_1, Y_2 = k_2, \dots, Y_p = k_p), \quad \forall \ c
\]</span></p>
<p>And whichever category <span class="math inline">\(c\)</span> for which the calculated probability is the highest is the category we assign unit <span class="math inline">\(t\)</span> to in <span class="math inline">\(\tilde\xi\)</span>.</p>
<p>Factor scores are estimated with the model, and can be accessed with</p>
</div>
<div id="tabset-8-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-8-3-tab">

</div>
</div>
</div>
<p><br></p>
</section>
<section id="structural-equation-modelling" class="level2" data-number="10.7">
<h2 data-number="10.7" class="anchored" data-anchor-id="structural-equation-modelling"><span class="header-section-number">10.7</span> Structural Equation Modelling</h2>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./identify.html" class="pagination-link" aria-label="Quasi-Experimental Methods">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Quasi-Experimental Methods</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./references.html" class="pagination-link" aria-label="References">
        <span class="nav-page-text">References</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>