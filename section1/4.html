<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Introductory Statistical Inference</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="4_files/libs/clipboard/clipboard.min.js"></script>
<script src="4_files/libs/quarto-html/quarto.js"></script>
<script src="4_files/libs/quarto-html/popper.min.js"></script>
<script src="4_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="4_files/libs/quarto-html/anchor.min.js"></script>
<link href="4_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="4_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="4_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="4_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="4_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99">
    <h2 id="toc-title">Chapters</h2>
   
  <ul>
  <li><a href="#preface" id="toc-preface" class="nav-link active" data-scroll-target="#preface">Preface</a></li>
  <li><a href="#chapter-1-statistical-inference" id="toc-chapter-1-statistical-inference" class="nav-link" data-scroll-target="#chapter-1-statistical-inference">Chapter 1: Statistical Inference</a>
  <ul class="collapse">
  <li><a href="#samples-and-population" id="toc-samples-and-population" class="nav-link" data-scroll-target="#samples-and-population">1.1: Samples and Population</a></li>
  <li><a href="#central-limit-theorem" id="toc-central-limit-theorem" class="nav-link" data-scroll-target="#central-limit-theorem">1.2: Central Limit Theorem</a></li>
  <li><a href="#t-distributions" id="toc-t-distributions" class="nav-link" data-scroll-target="#t-distributions">1.3: T-Distributions</a></li>
  </ul></li>
  <li><a href="#chapter-2-hypothesis-testing" id="toc-chapter-2-hypothesis-testing" class="nav-link" data-scroll-target="#chapter-2-hypothesis-testing">Chapter 2: Hypothesis Testing</a>
  <ul class="collapse">
  <li><a href="#hypothesis-testing" id="toc-hypothesis-testing" class="nav-link" data-scroll-target="#hypothesis-testing">2.1: Hypothesis Testing</a></li>
  <li><a href="#difference-of-means-test" id="toc-difference-of-means-test" class="nav-link" data-scroll-target="#difference-of-means-test">2.2: Difference of Means Test</a></li>
  </ul></li>
  <li><a href="#chapter-3-correlation" id="toc-chapter-3-correlation" class="nav-link" data-scroll-target="#chapter-3-correlation">Chapter 3: Correlation</a>
  <ul class="collapse">
  <li><a href="#covariance" id="toc-covariance" class="nav-link" data-scroll-target="#covariance">3.1: Covariance</a></li>
  <li><a href="#correlation-coefficient" id="toc-correlation-coefficient" class="nav-link" data-scroll-target="#correlation-coefficient">3.2: Correlation Coefficient</a></li>
  <li><a href="#best-linear-predictor" id="toc-best-linear-predictor" class="nav-link" data-scroll-target="#best-linear-predictor">3.3: Best Linear Predictor</a></li>
  </ul></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Introductory Statistical Inference</h1>
<p class="subtitle lead">Module 4 (Section 1: Core Statistical Methods)</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="preface" class="level1">
<h1>Preface</h1>
<p>Statistics allows us to describe relationships between variables, infer beyond samples, and provides the basis for causal inference. However, to utilise common statistical techniques such as regression or quasi-experimental techniques, we first need to understand statistical inference. This module starts off with an introduction to sampling and inference, then discusses hypothesis testing, and finishes with discussing correlation.</p>
<p><u>Prerequisites</u>: Section 0 (Or Equivalent)</p>
<hr>
<p><a href="https://politicalscience.github.io">Handbook Homepage</a></p>
</section>
<section id="chapter-1-statistical-inference" class="level1">
<h1>Chapter 1: Statistical Inference</h1>
<section id="samples-and-population" class="level3">
<h3 class="anchored" data-anchor-id="samples-and-population">1.1: Samples and Population</h3>
<p>In political science and the social sciences, we are often interested in studying large groups of people and entities. For example, we might be interested some feature regarding all people in a country, such as the average income, or average working hours, or average education level.</p>
<p>However, if we are dealing with large population sizes, it is often impossible to ask every single individual in the population. For example, if we wanted to study the average educational level of the UK, we would need to ask nearly 70 million people. This is completely impractical.</p>
<p><u>A sample is a subset of a population</u>, where ideally, the sample can tell us something about the population. If our sample can reflect the greater population, then we can use the sample in our study, instead of the large population.</p>
<p><br></p>
<p><u>Sampling</u> is the process by which we select a sample from a larger population. Like I just mentioned, we want the sample to be representative of the larger population, so that we can use the sample to make claims about the population.</p>
<p>To make sure the sample is representative of the population, we need to determine is a given sample is a good sample or a bad sample. The quality of sample depends on two major factors:</p>
<ol type="1">
<li>The sampling procedure which we decide to implement</li>
<li>Luck</li>
</ol>
<p>We will go back to luck in the future sections (hypothesis testing allows us to deal with that issue). Now, let us focus on sampling procedure.</p>
<p>The gold standard of sampling procedure is a <u>random sample</u> - where individuals in the sample are selected at random from the population. This is because in a random sample, every possible individual has an equal chance of being selected, and thus, the resulting sample is likely to be reflective of the common traits of the population.</p>
<p><br></p>
</section>
<section id="central-limit-theorem" class="level3">
<h3 class="anchored" data-anchor-id="central-limit-theorem">1.2: Central Limit Theorem</h3>
<p>Before we introduce the Central Limit Theorem, we need to explain a <u>distribution of sample means</u>.</p>
<ul>
<li><p>Imagine that we take a random sample from a population. Then, we find the mean of the variable we are interested in the sample. That is a sample mean.</p></li>
<li><p>Then, let us take another sample from the same population, and find the mean. This will be slightly different than the first sample, since we are randomly sampling. That is another sample mean.</p></li>
<li><p>We keep taking samples from the same population, and getting more and more sample means.</p></li>
<li><p>Now, let us plot all our sample means into a “histogram” or density plot. The <span class="math inline">\(x\)</span> axis labels the possible sample means values, and the <span class="math inline">\(y\)</span> axis is how frequently a specific sample mean occurs. We will get a distribution, just like a random variable distribution.</p></li>
<li><p>That distribution is the distribution of sample means - it basically measures the frequency of different sample means that we get, given we keep drawing samples from the same population and calculating their means.</p></li>
</ul>
<p><br></p>
<p><u>The Central Limit Theorem states that the distribution of sample means of a variable, will be distributed in a approximately normal distribution</u>. This is regardless of the variable’s population distribution shape.</p>
<ul>
<li>Essentially, no matter what distribution the population takes, if we take enough samples, the sample means plotted in a distribution will resemble a normal distribution.</li>
</ul>
<p>There are a few criteria for the Central Limit Theorem to be true:</p>
<ol type="1">
<li>The sample size (of the individual samples) should be at least 30</li>
<li>Sample independence - one sample’s results should not affect other sample’s results</li>
<li>Samples must be randomly sampled</li>
</ol>
<p>There are a few additional points:</p>
<ul>
<li><p>If the sample size condition is not met, but the population is normally distributed, we can still assume that central limit theorem occurs</p></li>
<li><p>If the sample size condition is not met, and the population is not normally distributed, we cannot use central limit theorem. The t-distribution may be of more use here.</p></li>
</ul>
<p><br></p>
<p><u>The Central Limit Theorem is arguably, the most important part of statistical inference</u>. Why? If we recall from <a href="https://politicalscience.github.io/section0/3.html#normal-distribution">Module 3, Chapter 3, Lesson 5</a>, the normal distribution has some key properties, which are very useful for statistical inference purposes.</p>
<p>If we recall, the normal distribution has the 68-95-99.7 rule (see <a href="https://politicalscience.github.io/section0/3.html#normal-distribution">Module 3, Chapter 3, Lesson 5</a> for a refresher)</p>
<p><img src="images/figure3-normal.png" class="img-fluid" style="width:90.0%"></p>
<p>Since the distribution of sample means tells us the probability of getting some sample mean, <u>we can now tell how likely a sample mean is to occur if a sample was drawn from the population</u>.</p>
<p>This goes back to the “luck” aspect of sampling. What if we are unlucky in sampling, and end up randomly drawing all the tall people? All the smartest people?</p>
<ul>
<li><p>Well, we can actually know how likely that we would pick such a sample!</p></li>
<li><p>Just use the distribution of the sample means, and since it is normally distributed, we can find how many standard deviations it is from the mean, and thus, calculate how likely that sample is to occur!</p></li>
<li><p>For example, if a certain sample mean is located 2 standard deviations above the mean, there is only a 2.14% chance that that sample mean would be that value or higher (see figure above)</p></li>
</ul>
<p><u>Thus, Central Limit Theorem allows us to account for the luck aspect of sampling</u>.</p>
<p><br></p>
</section>
<section id="t-distributions" class="level3">
<h3 class="anchored" data-anchor-id="t-distributions">1.3: T-Distributions</h3>
<p>The t-distribution is a distribution very similar to that of a normal distribution, with the bell-shape, however, it has a shorter peak, and thicker tails.. It is basically a <u>normal distribution, but designed to account for smaller sample sizes</u></p>
<p>T-distributions are used when our sample size is too small to meet the Central Limit Theorem, and our population underneath is not normally distributed. T-distributions are also used in the t-Difference of Means test, which we will explore later.</p>
<p><br></p>
<p>Unlike the normal distribution, which has the parameters of mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>, the t-Distribution only has one parameter - degrees of freedom <span class="math inline">\(DF\)</span></p>
<ul>
<li>We will talk about how to calculate <span class="math inline">\(DF\)</span> when we use the t-distribution in statistical tests. It is usually the number of observations in a sample <span class="math inline">\(n\)</span> minus the number of variables involved (typically 1 or 2).</li>
</ul>
<p>Just know in general, when <span class="math inline">\(DF\)</span> becomes higher, the tails become thinner and the peak becomes higher. When <span class="math inline">\(DF\)</span> becomes lower, the tails become thicker and the peak becomes lower.</p>
<ul>
<li>Around 30 <span class="math inline">\(DF\)</span>, the t-test approximates a standard normal distribution. This is why we generally switch the Central Limit Theorem to the t-Distribution under 30 sample size.</li>
</ul>
<p><br></p>
<hr>
<p><a href="https://politicalscience.github.io">Handbook Homepage</a></p>
</section>
</section>
<section id="chapter-2-hypothesis-testing" class="level1">
<h1>Chapter 2: Hypothesis Testing</h1>
<section id="hypothesis-testing" class="level3">
<h3 class="anchored" data-anchor-id="hypothesis-testing">2.1: Hypothesis Testing</h3>
<p>Hypothesis testing allows us to test a hypothesis (the hypothesis we are interested in is called the alternate hypothesis <span class="math inline">\(H_1\)</span>.</p>
<ul>
<li><p>We always start with the <u>null hypothesis</u>. The null is what we call the assumption that there is no difference/relationship - it is basically the “status-quo”. It is often labeled as <span class="math inline">\(H_0\)</span></p></li>
<li><p>The <u>alternate hypothesis</u> is the hypothesis we are trying to prove. It is often labeled as <span class="math inline">\(H_1\)</span></p></li>
</ul>
<p><u>We assume the null hypothesis (status-quo) is true, unless we are 95% confident we can reject the null hypothesis, and only then, can we conclude that the alternate hypothesis (the one of interest to us) is true</u>.</p>
<p>We will discuss what 95% confidence means when we do a difference-of-means test later.</p>
<p><br></p>
<p>Of course, with 95% confidence, we will have errors. There are two types of errors:</p>
<ol type="1">
<li><u>Type-I error</u>: this is when the null hypothesis is actually correct in the real world, but we accidentally reject it.</li>
<li><u>Type-II error</u>: This is when the null hypothesis is actually wrong in the real world, but we accidentally do not reject it</li>
</ol>
<p>You might ask, why 95%? Well, it is just convention in the social sciences. Other fields may have different confidence levels - for example, in drug trials, it is much much higher - since it would be a disaster to approve a faulty drug.</p>
<ul>
<li>There is nothing special about 95%, in fact many argue it is a bad measure. After all, what makes something magically better being 95% confident than 94% confident?</li>
</ul>
<p><br></p>
</section>
<section id="difference-of-means-test" class="level3">
<h3 class="anchored" data-anchor-id="difference-of-means-test">2.2: Difference of Means Test</h3>
<p><br></p>
<hr>
<p><a href="https://politicalscience.github.io">Handbook Homepage</a></p>
</section>
</section>
<section id="chapter-3-correlation" class="level1">
<h1>Chapter 3: Correlation</h1>
<section id="covariance" class="level3">
<h3 class="anchored" data-anchor-id="covariance">3.1: Covariance</h3>
<p>In political science, we are often interested in the relationship between two variables. For example, are oil producers more likely to be democratic? Are more educated voters more likely to turn out and vote?</p>
<p>The relationship between two features, also called correlation, is the extent to which they tend to occur together.</p>
<ul>
<li><p>A positive correlation/relationship is when we are more likely to observe feature <span class="math inline">\(Y\)</span>, if feature <span class="math inline">\(X\)</span> is present</p></li>
<li><p>A negative correlation/relationship is when we are less likely to observe feature <span class="math inline">\(Y\)</span>, if feature <span class="math inline">\(X\)</span> is present</p></li>
<li><p>No correlation/relationship is when we see feature <span class="math inline">\(X\)</span>, it doesn’t tell us anything about the likelihood of observing <span class="math inline">\(Y\)</span></p></li>
</ul>
<p>Graphically, a positive and negative correlation are as follows:</p>
<p><img src="figures/4-correlation.png" class="img-fluid" style="width:100.0%"></p>
<p><br></p>
<p>Covariance is a way to measure to relationship between two variables. Essentially, <u>covariance is the extent that <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> vary together</u>. Covariance is calculated as follows:</p>
<p><span class="math display">\[
Cov(X,Y) = \sigma_{XY} = \frac{\sum (X_i - E[X])(Y_i - E[Y])}{n}
\]</span></p>
<p>These are the parts of the equation:</p>
<ul>
<li>In our data, we have many different pairs of data points <span class="math inline">\((X_i, Y_i)\)</span></li>
<li><span class="math inline">\(X_i\)</span> is some point of <span class="math inline">\(X\)</span>, while <span class="math inline">\(E[X]\)</span> is the mean of <span class="math inline">\(X\)</span>. Same goes for <span class="math inline">\(Y_i\)</span> and <span class="math inline">\(E[Y]\)</span></li>
<li>Thus, <span class="math inline">\(X_i - E[X]\)</span> is the distance between any point <span class="math inline">\(X_i\)</span> and its mean <span class="math inline">\(E[X]\)</span>. Same goes for <span class="math inline">\(Y_i - E[Y]\)</span></li>
<li><span class="math inline">\(n\)</span> is the number of observations in our data.</li>
</ul>
<p><br></p>
<p><u>We can interpret the sign of the covariance</u>: if it is positive, we have a positive relationship. if it is negative, we have a negative relationship.</p>
<p>However, <u>we cannot interpret the size of the covariance</u>. This is because covariance is sensitive to the way we measure <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span></p>
<ul>
<li>For example, let us consider that <span class="math inline">\(X\)</span> is a measurement of age. We could measure age in years, or months. But by measuring in months, we are increasing all values of <span class="math inline">\(X\)</span> by 12 times. Yet, the data, and its variation are still exactly the same - we just changed the scale. However, covariance will also increase.</li>
</ul>
<p><br></p>
</section>
<section id="correlation-coefficient" class="level3">
<h3 class="anchored" data-anchor-id="correlation-coefficient">3.2: Correlation Coefficient</h3>
<p>Like we just mentioned, the magnitude of covariance cannot be measured. However, we can “normalise” covariance, so that measurement scale does not impact the value. We do this by dividing the covariance by the standard deviation of <span class="math inline">\(X\)</span> multiplied by the standard deviation of <span class="math inline">\(Y\)</span></p>
<p>This standardised version of covariance is called the <u>correlation coefficient, which is always between -1 and 1</u>. Thus, this allows us to <u>measure the strength of a correlation</u>. The formula is as follows:</p>
<p><span class="math display">\[
Corr(X,Y) = r = \rho= \frac{Cov(X,Y)}{\sigma_X \sigma_Y}
\]</span></p>
<p>Just like covariance, the sign of the correlation coefficient tells us the direction of relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span></p>
<p>However, we can also interpret the <u>strength of a correlation</u> through the correlation coefficient</p>
<ul>
<li><p>Closer to -1 or 1 means a strong negative/positive correlation</p></li>
<li><p>Closer to 0 means a weaker negative/positive correlation</p></li>
</ul>
<p>Below is a figure of different plots. Plots <span class="math inline">\(a,b,c\)</span> have positive correlation coefficients, and plots <span class="math inline">\(d,e,f\)</span> have negative correlation coefficients. Plots <span class="math inline">\(a\)</span> and <span class="math inline">\(d\)</span> have strong correlations (close to ±1), plots <span class="math inline">\(b\)</span> and <span class="math inline">\(e\)</span> have moderately strong correlations (close to ±0.5), and plots <span class="math inline">\(c\)</span> and <span class="math inline">\(f\)</span> have weak correlations (close to 0)</p>
<p><img src="figures/4-corrStrength.png" class="img-fluid" style="width:100.0%"></p>
<p><br></p>
<p>There is one extension of the correlation coefficient - called the <u>r-squared value</u>. R-squared is exactly what it sounds like - the correlation coefficient squared. Since it is squared, the r-squared value is always between 0 and 1.</p>
<p>The r-squared is useful because it gets rid of the sign on the correlation coefficient, and thus, only shows the strength of the relationship between two variables. More accurately, the r-squared value shows the percentage of variation of <span class="math inline">\(Y\)</span> explained by <span class="math inline">\(X\)</span></p>
<p>The r-squared value will become especially important as we dive into regression - especially multivariate models, since the r-squared value can tell us generally how “good” our models are at predicting <span class="math inline">\(Y\)</span> from <span class="math inline">\(X\)</span></p>
<p><br></p>
</section>
<section id="best-linear-predictor" class="level3">
<h3 class="anchored" data-anchor-id="best-linear-predictor">3.3: Best Linear Predictor</h3>
<p>While correlation coefficient tells us the strength of the correlation, it doesn’t tell us anything about the magnitude of the relationship. For example, if <span class="math inline">\(X\)</span> increases by 1, how much does <span class="math inline">\(Y\)</span> increase by?</p>
<ul>
<li>Magnitude is quite important - after all, even if two values are very highly correlated, if an increase in <span class="math inline">\(X\)</span> only leads to a miniscule increase in <span class="math inline">\(Y\)</span>, this might not be very important for understanding the world</li>
</ul>
<p><br></p>
<p>A way to estimate the magnitude of the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is the <u>best linear predictor</u>. The best linear predictor is a linear function <span class="math inline">\(Y = \alpha + \beta X\)</span> that best predicts <span class="math inline">\(Y\)</span> with values of <span class="math inline">\(X\)</span>. Essentially, it is a best fit line to our correlation</p>
<ul>
<li>If you need a refresher on how linear equations work, see <a href="https://politicalscience.github.io/section0/1.html#linear-equations-and-slope">Module 1, Chapter 1, Lesson 3</a></li>
</ul>
<p>For example, the figure below shows a best fit line for a set of data:</p>
<p><img src="figures/4-bestfit.png" class="img-fluid" style="width:70.0%"></p>
<p><br></p>
<p>We know the best fit linear prediction line takes the form <span class="math inline">\(Y = \alpha + \beta X\)</span>. But what value should the y-intercept <span class="math inline">\(\alpha\)</span> and the slope <span class="math inline">\(\beta\)</span> be?</p>
<ul>
<li>For example, in the figure above, why not draw a line that is slightly steeper? or draw a line a little lower?</li>
</ul>
<p>Well, the way we find the best fit line is quite intuitive - we want to reduce the error between our line, and the actual data points.</p>
<p>The “error”, also called the residual, is basically, how far away is our line from the points in the data. It is the actual <span class="math inline">\(Y\)</span> value from our dataset, minus the predicted <span class="math inline">\(Y\)</span> value from our linear equation for any given point <span class="math inline">\((x, y)\)</span>. Mathematically, it is <span class="math inline">\(y_i - \hat{y}_i\)</span>. For example, take the figure below, which shows the errors in red for every point in a dataset for 3 different best fit lines:</p>
<p><img src="figures/4-residuals.png" class="img-fluid" style="width:100.0%"></p>
<p>Essentially, we want to find the y-intercept <span class="math inline">\(\alpha\)</span> and slope <span class="math inline">\(\beta\)</span> of a linear line that <u>minimises the sum of squared errors</u> - which is exactly what it sounds like: every error squared, then sum of all of the squares. Sum of Squared errors is also called the Residual Sum of Squares, and mathematically:</p>
<p><span class="math display">\[
RSS = \sum(y_i - \hat{y}_i)^2
\]</span></p>
<p>The reason we square the errors is to get rid of the negative signs. This is because, the negative errors will simply cancel out the positive errors. But, we don’t want that - we want some measure of the total amount of error. Thus, the square makes all the negatives positive, which allows us to measure the magnitude of the errors, not the direction.</p>
<p><br></p>
<p>Well, now that we know we want to minimise the sum of squared errors, how do we actually get the slope <span class="math inline">\(\beta\)</span> and y-intercept <span class="math inline">\(\alpha\)</span> for our linear model? We of course, could try thousands/millions of different lines, and see which one has the lowest sum of squares</p>
<p>Or, we can use a mathematical estimator to estimate the optimal <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\alpha\)</span>. The most common estimator of the slope <span class="math inline">\(\beta\)</span> and y-intercept <span class="math inline">\(\alpha\)</span> is called the <u>Ordinary Least Squares (OLS) Estimator</u>. We will start with this estimator, and the linear model as a whole, in the next module.</p>
<p><br></p>
<hr>
<p><a href="https://politicalscience.github.io">Handbook Homepage</a></p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>